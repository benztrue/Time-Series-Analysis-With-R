<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 9 Regression | Time Series Analysis With R</title>
  <meta name="description" content="Chapter 9 Regression | Time Series Analysis With R" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 9 Regression | Time Series Analysis With R" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 9 Regression | Time Series Analysis With R" />
  
  
  

<meta name="author" content="Nicola Righetti" />


<meta name="date" content="2021-05-27" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="correlations-and-arima.html"/>
<link rel="next" href="intervention-analysis.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Time Series with R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Time Series Analysis With R</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#objectives"><i class="fa fa-check"></i><b>1.1</b> Objectives</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#lectures"><i class="fa fa-check"></i><b>1.2</b> Lectures</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#home-work"><i class="fa fa-check"></i><b>1.3</b> Home Work</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#assessment"><i class="fa fa-check"></i><b>1.4</b> Assessment</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#syllabus-and-readings"><i class="fa fa-check"></i><b>1.5</b> Syllabus and readings</a></li>
<li class="chapter" data-level="1.6" data-path="index.html"><a href="index.html#further-information-and-support"><i class="fa fa-check"></i><b>1.6</b> Further information and support</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="getting-started-with-r.html"><a href="getting-started-with-r.html"><i class="fa fa-check"></i><b>2</b> Getting started with R</a><ul>
<li class="chapter" data-level="2.1" data-path="getting-started-with-r.html"><a href="getting-started-with-r.html#rstudio-interface-and-data"><i class="fa fa-check"></i><b>2.1</b> RStudio Interface and Data</a><ul>
<li class="chapter" data-level="2.1.1" data-path="getting-started-with-r.html"><a href="getting-started-with-r.html#download-and-install-rstudio"><i class="fa fa-check"></i><b>2.1.1</b> Download and Install RStudio</a></li>
<li class="chapter" data-level="2.1.2" data-path="getting-started-with-r.html"><a href="getting-started-with-r.html#create-a-rstudio-project-and-import-data"><i class="fa fa-check"></i><b>2.1.2</b> Create a RStudio Project and Import data</a></li>
<li class="chapter" data-level="2.1.3" data-path="getting-started-with-r.html"><a href="getting-started-with-r.html#create-a-script"><i class="fa fa-check"></i><b>2.1.3</b> Create a Script</a></li>
<li class="chapter" data-level="2.1.4" data-path="getting-started-with-r.html"><a href="getting-started-with-r.html#the-rstudio-user-interface"><i class="fa fa-check"></i><b>2.1.4</b> The RStudio User Interface</a></li>
<li class="chapter" data-level="2.1.5" data-path="getting-started-with-r.html"><a href="getting-started-with-r.html#load-and-save-data"><i class="fa fa-check"></i><b>2.1.5</b> Load and Save Data</a></li>
<li class="chapter" data-level="2.1.6" data-path="getting-started-with-r.html"><a href="getting-started-with-r.html#create-new-folders"><i class="fa fa-check"></i><b>2.1.6</b> Create new Folders</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="getting-started-with-r.html"><a href="getting-started-with-r.html#basic-r"><i class="fa fa-check"></i><b>2.2</b> Basic R</a><ul>
<li class="chapter" data-level="2.2.1" data-path="getting-started-with-r.html"><a href="getting-started-with-r.html#objects"><i class="fa fa-check"></i><b>2.2.1</b> Objects</a></li>
<li class="chapter" data-level="2.2.2" data-path="getting-started-with-r.html"><a href="getting-started-with-r.html#functions"><i class="fa fa-check"></i><b>2.2.2</b> Functions</a></li>
<li class="chapter" data-level="2.2.3" data-path="getting-started-with-r.html"><a href="getting-started-with-r.html#data-types"><i class="fa fa-check"></i><b>2.2.3</b> Data Types</a></li>
<li class="chapter" data-level="2.2.4" data-path="getting-started-with-r.html"><a href="getting-started-with-r.html#excercise"><i class="fa fa-check"></i><b>2.2.4</b> Excercise</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="basic-data-wrangling-with-tidyverse.html"><a href="basic-data-wrangling-with-tidyverse.html"><i class="fa fa-check"></i><b>3</b> Basic Data Wrangling with Tidyverse</a><ul>
<li class="chapter" data-level="3.1" data-path="basic-data-wrangling-with-tidyverse.html"><a href="basic-data-wrangling-with-tidyverse.html#the-pipe-operator"><i class="fa fa-check"></i><b>3.1</b> The Pipe Operator %&gt;%</a></li>
<li class="chapter" data-level="3.2" data-path="basic-data-wrangling-with-tidyverse.html"><a href="basic-data-wrangling-with-tidyverse.html#mutate"><i class="fa fa-check"></i><b>3.2</b> Mutate</a></li>
<li class="chapter" data-level="3.3" data-path="basic-data-wrangling-with-tidyverse.html"><a href="basic-data-wrangling-with-tidyverse.html#rename"><i class="fa fa-check"></i><b>3.3</b> Rename</a></li>
<li class="chapter" data-level="3.4" data-path="basic-data-wrangling-with-tidyverse.html"><a href="basic-data-wrangling-with-tidyverse.html#summarize-and-group_by"><i class="fa fa-check"></i><b>3.4</b> Summarize and group_by</a><ul>
<li class="chapter" data-level="3.4.1" data-path="basic-data-wrangling-with-tidyverse.html"><a href="basic-data-wrangling-with-tidyverse.html#count-occurrences"><i class="fa fa-check"></i><b>3.4.1</b> Count occurrences</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="basic-data-wrangling-with-tidyverse.html"><a href="basic-data-wrangling-with-tidyverse.html#arrange"><i class="fa fa-check"></i><b>3.5</b> Arrange</a></li>
<li class="chapter" data-level="3.6" data-path="basic-data-wrangling-with-tidyverse.html"><a href="basic-data-wrangling-with-tidyverse.html#filter"><i class="fa fa-check"></i><b>3.6</b> Filter</a></li>
<li class="chapter" data-level="3.7" data-path="basic-data-wrangling-with-tidyverse.html"><a href="basic-data-wrangling-with-tidyverse.html#select"><i class="fa fa-check"></i><b>3.7</b> Select</a></li>
<li class="chapter" data-level="3.8" data-path="basic-data-wrangling-with-tidyverse.html"><a href="basic-data-wrangling-with-tidyverse.html#exercise"><i class="fa fa-check"></i><b>3.8</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="basic-concepts.html"><a href="basic-concepts.html"><i class="fa fa-check"></i><b>4</b> Basic Concepts</a><ul>
<li class="chapter" data-level="4.1" data-path="basic-concepts.html"><a href="basic-concepts.html#time-series"><i class="fa fa-check"></i><b>4.1</b> Time Series</a></li>
<li class="chapter" data-level="4.2" data-path="basic-concepts.html"><a href="basic-concepts.html#time-series-analysis"><i class="fa fa-check"></i><b>4.2</b> Time Series Analysis</a></li>
<li class="chapter" data-level="4.3" data-path="basic-concepts.html"><a href="basic-concepts.html#stochastic-and-deterministic-processes"><i class="fa fa-check"></i><b>4.3</b> Stochastic and Deterministic Processes</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="time-series-objects.html"><a href="time-series-objects.html"><i class="fa fa-check"></i><b>5</b> Time Series Objects</a><ul>
<li class="chapter" data-level="5.1" data-path="time-series-objects.html"><a href="time-series-objects.html#time-series-objects-1"><i class="fa fa-check"></i><b>5.1</b> Time Series Objects</a><ul>
<li class="chapter" data-level="5.1.1" data-path="time-series-objects.html"><a href="time-series-objects.html#time-series-as-data-frames"><i class="fa fa-check"></i><b>5.1.1</b> Time Series as Data Frames</a></li>
<li class="chapter" data-level="5.1.2" data-path="time-series-objects.html"><a href="time-series-objects.html#time-series-as-ts-objects"><i class="fa fa-check"></i><b>5.1.2</b> Time Series as TS objects</a></li>
<li class="chapter" data-level="5.1.3" data-path="time-series-objects.html"><a href="time-series-objects.html#time-series-as-xtszoo-objects"><i class="fa fa-check"></i><b>5.1.3</b> Time Series as XTS/ZOO objects</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="time-series-objects.html"><a href="time-series-objects.html#exercise-1"><i class="fa fa-check"></i><b>5.2</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="plot-time-series.html"><a href="plot-time-series.html"><i class="fa fa-check"></i><b>6</b> Plot Time Series</a><ul>
<li class="chapter" data-level="6.1" data-path="plot-time-series.html"><a href="plot-time-series.html#plot-time-series-objects"><i class="fa fa-check"></i><b>6.1</b> Plot Time Series Objects</a></li>
<li class="chapter" data-level="6.2" data-path="plot-time-series.html"><a href="plot-time-series.html#plot.ts"><i class="fa fa-check"></i><b>6.2</b> plot.ts</a></li>
<li class="chapter" data-level="6.3" data-path="plot-time-series.html"><a href="plot-time-series.html#plot.xts"><i class="fa fa-check"></i><b>6.3</b> plot.xts</a></li>
<li class="chapter" data-level="6.4" data-path="plot-time-series.html"><a href="plot-time-series.html#ggplot"><i class="fa fa-check"></i><b>6.4</b> ggplot</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="structural-decomposition.html"><a href="structural-decomposition.html"><i class="fa fa-check"></i><b>7</b> Structural Decomposition</a><ul>
<li class="chapter" data-level="7.1" data-path="structural-decomposition.html"><a href="structural-decomposition.html#components-of-a-time-series"><i class="fa fa-check"></i><b>7.1</b> Components of a time series</a><ul>
<li class="chapter" data-level="7.1.1" data-path="structural-decomposition.html"><a href="structural-decomposition.html#trend-and-cycle"><i class="fa fa-check"></i><b>7.1.1</b> Trend and Cycle</a></li>
<li class="chapter" data-level="7.1.2" data-path="structural-decomposition.html"><a href="structural-decomposition.html#seasonality"><i class="fa fa-check"></i><b>7.1.2</b> Seasonality</a></li>
<li class="chapter" data-level="7.1.3" data-path="structural-decomposition.html"><a href="structural-decomposition.html#residuals"><i class="fa fa-check"></i><b>7.1.3</b> Residuals</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="structural-decomposition.html"><a href="structural-decomposition.html#structural-decomposition-1"><i class="fa fa-check"></i><b>7.2</b> Structural decomposition</a><ul>
<li class="chapter" data-level="7.2.1" data-path="structural-decomposition.html"><a href="structural-decomposition.html#moving-average"><i class="fa fa-check"></i><b>7.2.1</b> Moving Average</a></li>
<li class="chapter" data-level="7.2.2" data-path="structural-decomposition.html"><a href="structural-decomposition.html#decompose"><i class="fa fa-check"></i><b>7.2.2</b> Decompose</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="structural-decomposition.html"><a href="structural-decomposition.html#adjust-time-series"><i class="fa fa-check"></i><b>7.3</b> Adjust time series</a><ul>
<li class="chapter" data-level="7.3.1" data-path="structural-decomposition.html"><a href="structural-decomposition.html#seasonal-adjusted-data"><i class="fa fa-check"></i><b>7.3.1</b> Seasonal adjusted data</a></li>
<li class="chapter" data-level="7.3.2" data-path="structural-decomposition.html"><a href="structural-decomposition.html#detrended-series"><i class="fa fa-check"></i><b>7.3.2</b> Detrended series</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="structural-decomposition.html"><a href="structural-decomposition.html#white-noise-and-stationarity"><i class="fa fa-check"></i><b>7.4</b> White Noise and Stationarity</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="correlations-and-arima.html"><a href="correlations-and-arima.html"><i class="fa fa-check"></i><b>8</b> Correlations and ARIMA</a><ul>
<li class="chapter" data-level="8.1" data-path="correlations-and-arima.html"><a href="correlations-and-arima.html#auto-correlation-acf-and-pacf"><i class="fa fa-check"></i><b>8.1</b> Auto-Correlation (ACF and PACF)</a><ul>
<li class="chapter" data-level="8.1.1" data-path="correlations-and-arima.html"><a href="correlations-and-arima.html#correlogram-acf-and-pacf"><i class="fa fa-check"></i><b>8.1.1</b> Correlogram: ACF and PACF</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="correlations-and-arima.html"><a href="correlations-and-arima.html#arima-models"><i class="fa fa-check"></i><b>8.2</b> ARIMA models</a><ul>
<li class="chapter" data-level="8.2.1" data-path="correlations-and-arima.html"><a href="correlations-and-arima.html#auto-regressive-ar-models"><i class="fa fa-check"></i><b>8.2.1</b> Auto Regressive (AR) models</a></li>
<li class="chapter" data-level="8.2.2" data-path="correlations-and-arima.html"><a href="correlations-and-arima.html#moving-average-ma-models"><i class="fa fa-check"></i><b>8.2.2</b> Moving Average (MA) models</a></li>
<li class="chapter" data-level="8.2.3" data-path="correlations-and-arima.html"><a href="correlations-and-arima.html#integrated-i-process"><i class="fa fa-check"></i><b>8.2.3</b> Integrated (I) process</a></li>
<li class="chapter" data-level="8.2.4" data-path="correlations-and-arima.html"><a href="correlations-and-arima.html#seasonal-s-models"><i class="fa fa-check"></i><b>8.2.4</b> Seasonal (S) models</a></li>
<li class="chapter" data-level="8.2.5" data-path="correlations-and-arima.html"><a href="correlations-and-arima.html#fit-sarima-models"><i class="fa fa-check"></i><b>8.2.5</b> Fit (S)ARIMA models</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="correlations-and-arima.html"><a href="correlations-and-arima.html#cross-correlation"><i class="fa fa-check"></i><b>8.3</b> Cross-correlation</a></li>
<li class="chapter" data-level="8.4" data-path="correlations-and-arima.html"><a href="correlations-and-arima.html#examples-in-literature"><i class="fa fa-check"></i><b>8.4</b> Examples in literature</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="regression.html"><a href="regression.html"><i class="fa fa-check"></i><b>9</b> Regression</a><ul>
<li class="chapter" data-level="9.1" data-path="regression.html"><a href="regression.html#static-and-dynamic-models"><i class="fa fa-check"></i><b>9.1</b> Static and Dynamic Models</a></li>
<li class="chapter" data-level="9.2" data-path="regression.html"><a href="regression.html#regression-models"><i class="fa fa-check"></i><b>9.2</b> Regression models</a><ul>
<li class="chapter" data-level="9.2.1" data-path="regression.html"><a href="regression.html#non-autocorrelated-residuals"><i class="fa fa-check"></i><b>9.2.1</b> Non-autocorrelated residuals</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="regression.html"><a href="regression.html#regression-with-arima-errors"><i class="fa fa-check"></i><b>9.3</b> Regression with ARIMA errors</a></li>
<li class="chapter" data-level="9.4" data-path="regression.html"><a href="regression.html#some-examples-in-the-literature"><i class="fa fa-check"></i><b>9.4</b> Some examples in the literature</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="intervention-analysis.html"><a href="intervention-analysis.html"><i class="fa fa-check"></i><b>10</b> Intervention Analysis</a></li>
<li class="chapter" data-level="11" data-path="readings.html"><a href="readings.html"><i class="fa fa-check"></i><b>11</b> Readings</a><ul>
<li class="chapter" data-level="11.1" data-path="readings.html"><a href="readings.html#bibliographical-references"><i class="fa fa-check"></i><b>11.1</b> Bibliographical References</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Time Series Analysis With R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="regression" class="section level1">
<h1><span class="header-section-number">Chapter 9</span> Regression</h1>
<p>In this chapter we are going to see how to conduct a regression analysis with time series data.</p>
<p><em>Regression analysis</em> is a set of statistical processes for estimating the relationships between a <em>dependent variable (DV)</em> (also called <em>outcome</em> or <em>response</em>) and one or more <em>independent variables (IV)</em> (also called <em>predictors</em> or <em>explanatory variables</em>).</p>
<p>A standard regression model <span class="math inline">\(Y\)</span> = <span class="math inline">\(\beta\)</span> + <span class="math inline">\(\beta x\)</span> + <span class="math inline">\(\epsilon\)</span> has no time component. Differently, a time series regression model includes a time dimension and can be written, in a simple and general formulation using just one explanatory variable, as follows:</p>
<p><span class="math display">\[
y_t = \beta_0 + \beta_1x_t + \epsilon_t
\]</span></p>
<p>In this equation, <span class="math inline">\(y_t\)</span> is the time series we try to understand and predict (the <em>dependent variable (DV)</em>), <span class="math inline">\(\beta_0\)</span> is the <em>intercept</em> (a constant value that represents the expected mean value of <span class="math inline">\(y_t\)</span> when <span class="math inline">\(x_t = 0\)</span>), the coefficient <span class="math inline">\(\beta_1\)</span> is the <em>slope</em>, representing the average change in <span class="math inline">\(y\)</span> at one unit increase in <span class="math inline">\(x\)</span> (the <em>independent variable (IV) or explanatory variable</em>), and <span class="math inline">\(\epsilon_t\)</span> is the time series of residuals (the error term).</p>
<p>A multiple regression form, with more than one explanatory variable, can be written as follows:</p>
<p><span class="math display">\[
y_t = \beta_0 + \beta_1x_{1,t} + \beta_2x_{2,t} + ... + \beta_kx_{k,t} + \epsilon_t
\]</span></p>
<div id="static-and-dynamic-models" class="section level2">
<h2><span class="header-section-number">9.1</span> Static and Dynamic Models</h2>
<p>From a time series analysis perspective, a general distinction can be made between “static” and “dynamic” regression models:</p>
<ul>
<li>A <strong>static regression model</strong> includes just contemporary relations between the explanatory variables (independent variables) and the response (dependent variable). This model could be appropriate when the expected value of the response changes <em>immediately</em> when the value of the explanatory variable changes. Considering a model with <span class="math inline">\(k\)</span> independent variables {<span class="math inline">\(x_1\)</span>, <span class="math inline">\(x_2\)</span>, …, <span class="math inline">\(x_k\)</span>}, a static (multiple) regression model, has the form just seen above:</li>
</ul>
<p><span class="math display">\[
y_t = \beta_0 + \beta_1x_{1,t} + \beta_2x_{2,t} + ... + \beta_kx_{k,t} + \epsilon_t
\]</span></p>
<p>Each <span class="math inline">\(\beta\)</span> coefficient models the <em>instant change</em> in the conditional expected value of the response variable <span class="math inline">\(y_t\)</span> as the value of <span class="math inline">\(x_{k,t}\)</span> changes by one unit, keeping constant all the other predictors (i.e.: the other <span class="math inline">\(x_{k,t}\)</span>):</p>
<ul>
<li>A <strong>dynamic regression model</strong> includes relations between <em>both the current and the lagged (past) values of the explanatory (independent) variables</em>, that is, the expected value of the response variable may change <em>after</em> a change in the values of the explanatory variables.</li>
</ul>
<p><span class="math display">\[
\begin{aligned} 
y_t = \beta_0  &amp; + \beta_{10}x_{1,t} + \beta_{11}x_{1,t-1} + ... + \beta_{1m}x_{1,t-m} \\
&amp; + \beta_{20}x_{2,t} + \beta_{21}x_{2,t-1} + ... + \beta_{2m}x_{2,t-m} \\
&amp; + \dots \\
&amp; + \beta_{k0}x_{k,t} + \beta_{k1}x_{k,t-1} + ... + \beta_{km}x_{2,t-m} \\
&amp; + \epsilon_t \\
\end{aligned} 
\]</span></p>
<p>Despite the differences between these two analytic perspectives, the term <em>dynamic regression</em> is also used, in the literature, in a more general way to refer to regression models with autocorrelated errors, also when they are used to analyze only contemporary relations between variables.</p>
</div>
<div id="regression-models" class="section level2">
<h2><span class="header-section-number">9.2</span> Regression models</h2>
<p>Except for the possible use of lagged regressors, which are typical of time series, the above described statistical models are standard regression models, commonly used with cross-sectional data.</p>
<p>Standard linear regression models can sometimes work well enough with time series data, <strong>if specific conditions are met</strong>. Besides standard assumptions of linear regression<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>, a careful analysis should be done in order to ascertain that <strong>residuals are not autocorrelated</strong>, since this can determine problems in the estimated model.</p>
<p>Even before that, it is important that the series are <strong>stationary</strong>, in order to avoid possible spurious correlations. Since time series can be nonstationary due to different reasons, different strategies can be employed to <em>stationarize</em> the data.</p>
<p>For instance, a nonstationary series can be a series with <strong>unequal variance</strong> over time. A common way to try to fix the problem is applying the log-transformation.</p>
<div class="sourceCode" id="cb232"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb232-1"><a href="regression.html#cb232-1"></a><span class="kw">library</span>(xts)</span>
<span id="cb232-2"><a href="regression.html#cb232-2"></a></span>
<span id="cb232-3"><a href="regression.html#cb232-3"></a>elections_news &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;data/elections-stories-over-time-20210111144254.csv&quot;</span>)</span>
<span id="cb232-4"><a href="regression.html#cb232-4"></a>elections_news<span class="op">$</span>date &lt;-<span class="st"> </span><span class="kw">as.Date</span>(elections_news<span class="op">$</span>date)</span>
<span id="cb232-5"><a href="regression.html#cb232-5"></a></span>
<span id="cb232-6"><a href="regression.html#cb232-6"></a>elections_news &lt;-<span class="st"> </span><span class="kw">xts</span>(elections_news<span class="op">$</span>count, <span class="dt">order.by =</span> elections_news<span class="op">$</span>date)</span>
<span id="cb232-7"><a href="regression.html#cb232-7"></a>elections_news_log &lt;-<span class="st"> </span><span class="kw">log</span>(elections_news<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb232-8"><a href="regression.html#cb232-8"></a>elections_news_xts &lt;-<span class="st"> </span><span class="kw">merge.xts</span>(elections_news, elections_news_log)</span>
<span id="cb232-9"><a href="regression.html#cb232-9"></a></span>
<span id="cb232-10"><a href="regression.html#cb232-10"></a><span class="kw">plot.xts</span>(elections_news_xts, <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;blue&quot;</span>, <span class="st">&quot;red&quot;</span>),</span>
<span id="cb232-11"><a href="regression.html#cb232-11"></a>         <span class="dt">multi.panel =</span> <span class="ot">TRUE</span>, <span class="dt">yaxis.same =</span> <span class="ot">FALSE</span>,</span>
<span id="cb232-12"><a href="regression.html#cb232-12"></a>         <span class="dt">main =</span> <span class="st">&quot;Original vs Log-transformed series&quot;</span>)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-157-1.png" width="672" /></p>
<p>Another reason for nonstationarity are the periodic variations due to <strong>seasonality</strong>, regular fluctuations in a time series that follow a specific time pattern (e.g.: social media activity during week-ends, Christmas effect in consumption, etc.).</p>
<p>To remove the seasonal pattern, you might want to use a <em>seasonally-adjusted</em> time series. Otherwise, you could create a dummy variable for the seasonal period (that is, a variable that follows the seasonal pattern in the data in order to account, in the model, for these fluctuations).</p>
<div class="sourceCode" id="cb233"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb233-1"><a href="regression.html#cb233-1"></a><span class="co"># load the ts dataset AirPassenger</span></span>
<span id="cb233-2"><a href="regression.html#cb233-2"></a><span class="kw">data</span>(<span class="st">&quot;AirPassengers&quot;</span>)</span>
<span id="cb233-3"><a href="regression.html#cb233-3"></a></span>
<span id="cb233-4"><a href="regression.html#cb233-4"></a><span class="co"># remove seasonality from a multiplicative model</span></span>
<span id="cb233-5"><a href="regression.html#cb233-5"></a>AirPassengers_decomposed &lt;-<span class="st"> </span><span class="kw">decompose</span>(AirPassengers, <span class="dt">type=</span><span class="st">&quot;multiplicative&quot;</span>)</span>
<span id="cb233-6"><a href="regression.html#cb233-6"></a>AirPassengers_seasonal_component &lt;-<span class="st"> </span>AirPassengers_decomposed<span class="op">$</span>seasonal</span>
<span id="cb233-7"><a href="regression.html#cb233-7"></a>AirPassengers_seasonally_adjusted &lt;-<span class="st"> </span>AirPassengers<span class="op">/</span>AirPassengers_seasonal_component</span>
<span id="cb233-8"><a href="regression.html#cb233-8"></a></span>
<span id="cb233-9"><a href="regression.html#cb233-9"></a><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb233-10"><a href="regression.html#cb233-10"></a><span class="kw">plot.ts</span>(AirPassengers, <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">main =</span> <span class="st">&quot;Original series&quot;</span>)</span>
<span id="cb233-11"><a href="regression.html#cb233-11"></a><span class="kw">plot.ts</span>(AirPassengers_seasonally_adjusted, <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>,  </span>
<span id="cb233-12"><a href="regression.html#cb233-12"></a>        <span class="dt">main =</span> <span class="st">&quot;Seasonally-adjusted series&quot;</span>, </span>
<span id="cb233-13"><a href="regression.html#cb233-13"></a>        <span class="dt">ylab =</span> <span class="st">&quot;Seasonally-adjusted values&quot;</span>)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-158-1.png" width="672" /></p>
<p>An important reason for nonstationarity is also the presence of a trend in the data. There are <strong>stochastic</strong> and <strong>deterministic trends</strong>. Deterministic trends are a fixed function of time, while stochastic trends change in an unpredictable way.</p>
<p>Series with a deterministic trend are also called <em>trend stationary</em> because they can be stationary around a deterministic trend, and it could be possible to achieve stationarity by removing the time trend. In trend stationary processes, the shocks to the process are transitory and the process is <em>mean reverting</em>. Processes with a <em>stochastic trend</em> are also called <em>difference stationary</em> because they can become stationary through <em>differencing</em>. In series with stochastic trends we could see that shocks have permanent effects.</p>
<p>When dealing with <em>deterministic trend</em>, we might want to work with detrended series.</p>
<div class="sourceCode" id="cb234"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb234-1"><a href="regression.html#cb234-1"></a><span class="co"># remove the trend from a multiplicative model</span></span>
<span id="cb234-2"><a href="regression.html#cb234-2"></a>AirPassengers_decomposed &lt;-<span class="st"> </span><span class="kw">decompose</span>(AirPassengers, <span class="dt">type=</span><span class="st">&quot;multiplicative&quot;</span>)</span>
<span id="cb234-3"><a href="regression.html#cb234-3"></a>AirPassengers_trend_component &lt;-<span class="st"> </span>AirPassengers_decomposed<span class="op">$</span>trend</span>
<span id="cb234-4"><a href="regression.html#cb234-4"></a>AirPassengers_detrended &lt;-<span class="st"> </span>AirPassengers<span class="op">/</span>AirPassengers_trend_component</span>
<span id="cb234-5"><a href="regression.html#cb234-5"></a></span>
<span id="cb234-6"><a href="regression.html#cb234-6"></a><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb234-7"><a href="regression.html#cb234-7"></a><span class="kw">plot.ts</span>(AirPassengers, <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">main =</span> <span class="st">&quot;Original series&quot;</span>)</span>
<span id="cb234-8"><a href="regression.html#cb234-8"></a><span class="kw">plot.ts</span>(AirPassengers_detrended, <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>,  </span>
<span id="cb234-9"><a href="regression.html#cb234-9"></a>        <span class="dt">main =</span> <span class="st">&quot;Detrended series&quot;</span>, </span>
<span id="cb234-10"><a href="regression.html#cb234-10"></a>        <span class="dt">ylab =</span> <span class="st">&quot;Detrended values&quot;</span>)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-159-1.png" width="672" /></p>
<p>Otherwise, in regression analysis, it is also commonly add a dummy variable consisting of a value that increase with time, to account for a linear deterministic time trend. This time-count variable will remove the deterministic trend from the dependent variable, allowing the other predictors to explain the remaining variance.</p>
<div class="sourceCode" id="cb235"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb235-1"><a href="regression.html#cb235-1"></a><span class="co"># create a simulate series</span></span>
<span id="cb235-2"><a href="regression.html#cb235-2"></a><span class="kw">set.seed</span>(<span class="dv">1312</span>)</span>
<span id="cb235-3"><a href="regression.html#cb235-3"></a>toy_data &lt;-<span class="st"> </span><span class="kw">arima.sim</span>(<span class="dt">n =</span> <span class="dv">100</span>, <span class="dt">model =</span> <span class="kw">list</span>(<span class="dt">order =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>)))</span>
<span id="cb235-4"><a href="regression.html#cb235-4"></a></span>
<span id="cb235-5"><a href="regression.html#cb235-5"></a><span class="co"># add a deterministic trend to the series</span></span>
<span id="cb235-6"><a href="regression.html#cb235-6"></a>toy_data_trend &lt;-<span class="st"> </span>toy_data <span class="op">+</span><span class="st"> </span><span class="fl">0.2</span><span class="op">*</span><span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(toy_data)</span>
<span id="cb235-7"><a href="regression.html#cb235-7"></a></span>
<span id="cb235-8"><a href="regression.html#cb235-8"></a><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">3</span>))</span>
<span id="cb235-9"><a href="regression.html#cb235-9"></a><span class="kw">plot.ts</span>(toy_data, <span class="dt">main =</span> <span class="st">&quot;Original series&quot;</span>)</span>
<span id="cb235-10"><a href="regression.html#cb235-10"></a><span class="kw">plot.ts</span>(toy_data_trend, <span class="dt">main =</span> <span class="st">&quot;Series with Trend&quot;</span>)</span>
<span id="cb235-11"><a href="regression.html#cb235-11"></a></span>
<span id="cb235-12"><a href="regression.html#cb235-12"></a>dummy_trend &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(toy_data_trend)</span>
<span id="cb235-13"><a href="regression.html#cb235-13"></a>lm_toydata &lt;-<span class="st"> </span><span class="kw">lm</span>(toy_data_trend <span class="op">~</span><span class="st"> </span>dummy_trend)</span>
<span id="cb235-14"><a href="regression.html#cb235-14"></a><span class="kw">plot.ts</span>(lm_toydata<span class="op">$</span>residuals, <span class="dt">main =</span> <span class="st">&quot;Residuals (detrended)&quot;</span>)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-160-1.png" width="672" /></p>
<p>When we have a series with a stochastic trend, we can achieve stationarity through differencing.</p>
<div class="sourceCode" id="cb236"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb236-1"><a href="regression.html#cb236-1"></a><span class="kw">set.seed</span>(<span class="dv">111</span>)</span>
<span id="cb236-2"><a href="regression.html#cb236-2"></a>Random_Walk &lt;-<span class="st"> </span><span class="kw">arima.sim</span>(<span class="dt">n =</span> <span class="dv">500</span>, <span class="dt">model =</span> <span class="kw">list</span>(<span class="dt">order =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>)))</span>
<span id="cb236-3"><a href="regression.html#cb236-3"></a></span>
<span id="cb236-4"><a href="regression.html#cb236-4"></a>Random_Walk_diff &lt;-<span class="st"> </span><span class="kw">diff</span>(Random_Walk)</span>
<span id="cb236-5"><a href="regression.html#cb236-5"></a></span>
<span id="cb236-6"><a href="regression.html#cb236-6"></a><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb236-7"><a href="regression.html#cb236-7"></a><span class="kw">plot.ts</span>(Random_Walk,</span>
<span id="cb236-8"><a href="regression.html#cb236-8"></a>        <span class="dt">main =</span> <span class="st">&quot;Random Walk&quot;</span>, </span>
<span id="cb236-9"><a href="regression.html#cb236-9"></a>        <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;&quot;</span>)</span>
<span id="cb236-10"><a href="regression.html#cb236-10"></a></span>
<span id="cb236-11"><a href="regression.html#cb236-11"></a><span class="kw">plot.ts</span>(Random_Walk_diff, </span>
<span id="cb236-12"><a href="regression.html#cb236-12"></a>        <span class="dt">main =</span> <span class="st">&quot;Differenced Random Walk&quot;</span>, </span>
<span id="cb236-13"><a href="regression.html#cb236-13"></a>        <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;&quot;</span>)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-161-1.png" width="672" /></p>
<p>There are tests for detecting different types of trends. We will learn more about them in the next lecture.</p>
<div id="non-autocorrelated-residuals" class="section level3">
<h3><span class="header-section-number">9.2.1</span> Non-autocorrelated residuals</h3>
<p>To try a linear regression model we create some simulate series <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>, with <span class="math inline">\(x\)</span> correlated with <span class="math inline">\(y\)</span> at lags <span class="math inline">\(x_{t-3}\)</span> and <span class="math inline">\(x_{t-4}\)</span>.</p>
<div class="sourceCode" id="cb237"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb237-1"><a href="regression.html#cb237-1"></a><span class="co"># simulated data </span></span>
<span id="cb237-2"><a href="regression.html#cb237-2"></a><span class="co"># the x series is correlated at lag 3 and 4</span></span>
<span id="cb237-3"><a href="regression.html#cb237-3"></a><span class="kw">set.seed</span>(<span class="dv">999</span>)</span>
<span id="cb237-4"><a href="regression.html#cb237-4"></a>x_series &lt;-<span class="st"> </span><span class="kw">arima.sim</span>(<span class="dt">n =</span> <span class="dv">200</span>, <span class="kw">list</span>(<span class="dt">order =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>), <span class="dt">ar =</span> <span class="fl">0.7</span>, <span class="dt">sd=</span><span class="dv">1</span>))</span>
<span id="cb237-5"><a href="regression.html#cb237-5"></a>z &lt;-<span class="st"> </span><span class="kw">ts.intersect</span>(x_series, stats<span class="op">::</span><span class="kw">lag</span>(x_series, <span class="dv">-3</span>), stats<span class="op">::</span><span class="kw">lag</span>(x_series, <span class="dv">-4</span>)) </span>
<span id="cb237-6"><a href="regression.html#cb237-6"></a>y_series &lt;-<span class="st"> </span><span class="dv">15</span> <span class="op">+</span><span class="st"> </span><span class="fl">0.8</span><span class="op">*</span>z[,<span class="dv">2</span>] <span class="op">+</span><span class="st"> </span><span class="fl">1.5</span><span class="op">*</span>z[,<span class="dv">3</span>] <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">196</span>,<span class="dv">0</span>,<span class="dv">1</span>)</span>
<span id="cb237-7"><a href="regression.html#cb237-7"></a></span>
<span id="cb237-8"><a href="regression.html#cb237-8"></a>xLagged &lt;-<span class="st"> </span><span class="kw">cbind</span>(</span>
<span id="cb237-9"><a href="regression.html#cb237-9"></a>    <span class="dt">xLag0 =</span> x_series,</span>
<span id="cb237-10"><a href="regression.html#cb237-10"></a>    <span class="dt">xLag3 =</span> stats<span class="op">::</span><span class="kw">lag</span>(x_series,<span class="op">-</span><span class="dv">3</span>),</span>
<span id="cb237-11"><a href="regression.html#cb237-11"></a>    <span class="dt">xLag4 =</span> stats<span class="op">::</span><span class="kw">lag</span>(x_series,<span class="op">-</span><span class="dv">4</span>))</span>
<span id="cb237-12"><a href="regression.html#cb237-12"></a></span>
<span id="cb237-13"><a href="regression.html#cb237-13"></a>xy_series &lt;-<span class="st"> </span><span class="kw">ts.union</span>(y_series, xLagged)</span></code></pre></div>
<p>The <em>real</em> model (in this case we know it because we created it through the above simulation), is as follows:</p>
<p><span class="math display">\[
y_t = 15 + 0.8x_{t-3} + 1.5x_{t-4} + \epsilon_t \\
\epsilon \sim N(0, 1)
\]</span></p>
<p>Toi fit a linear regression, we use the function <strong>lm</strong> (it’s in base R, no additional packages are necessary).</p>
<div class="sourceCode" id="cb238"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb238-1"><a href="regression.html#cb238-1"></a>lm1 &lt;-<span class="st"> </span><span class="kw">lm</span>(xy_series[,<span class="dv">1</span>] <span class="op">~</span><span class="st"> </span>xy_series[,<span class="dv">3</span><span class="op">:</span><span class="dv">4</span>])</span></code></pre></div>
<p>The function <strong>summary</strong> is used to print the summary of the model, wich includes the estimates.</p>
<div class="sourceCode" id="cb239"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb239-1"><a href="regression.html#cb239-1"></a><span class="kw">summary</span>(lm1)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = xy_series[, 1] ~ xy_series[, 3:4])
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.56906 -0.72401  0.05896  0.74288  2.14534 
## 
## Coefficients:
##                               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)                   14.96732    0.07299  205.06   &lt;2e-16 ***
## xy_series[, 3:4]xLagged.xLag3  0.86046    0.07753   11.10   &lt;2e-16 ***
## xy_series[, 3:4]xLagged.xLag4  1.41678    0.07831   18.09   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.007 on 193 degrees of freedom
##   (8 observations deleted due to missingness)
## Multiple R-squared:  0.8698, Adjusted R-squared:  0.8684 
## F-statistic: 644.5 on 2 and 193 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>We said that regression models sometimes work well enough with time series data, if some conditions are met. Regards the conditions (or <strong>assumptions</strong>), in particular, the <strong>residuals</strong> of the models should have zero mean, they shouldn’t show any significant autocorrelation, and they should be normally distributed.</p>
<p>To check whether these assumptions are met, we can visualize the <em>plot of residuals, its ACF/PACF and histogram</em>, and also test the residuals for possible autocorrelation using a statistical test like the <a href="https://en.wikipedia.org/wiki/Breusch–Godfrey_test">Breusch-Godfrey test</a> (this test is the default in the forecast library when a linear regression object lm is tested).</p>
<p>To create the plots we can use the base R functions, or we can use the convenient <em>checkresiduals</em> function in the <em>forecast</em> package.</p>
<p>In this case everything seems fine.</p>
<div class="sourceCode" id="cb241"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb241-1"><a href="regression.html#cb241-1"></a><span class="co"># install.package(&quot;forecast&quot;) # install the package if necessary</span></span>
<span id="cb241-2"><a href="regression.html#cb241-2"></a><span class="kw">library</span>(forecast)</span>
<span id="cb241-3"><a href="regression.html#cb241-3"></a><span class="kw">checkresiduals</span>(lm1)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-165-1.png" width="672" /></p>
<pre><code>## 
##  Breusch-Godfrey test for serial correlation of order up to 10
## 
## data:  Residuals
## LM test = 9.0522, df = 10, p-value = 0.5272</code></pre>
<p>If we look at the model summary printed above, we can see that the estimated model is the following (the standard deviation of residuals is <a href="https://stat.ethz.ch/R-manual/R-devel/library/stats/html/sigma.html">misnamed as “residual standard error” in the summary of <em>lm</em></a>):</p>
<p><span class="math display">\[
\begin{equation} 
y_t = 14.96732 + 0.86046x_{t-3} + 1.41678x_{t-4} + \epsilon_t \\
\epsilon \sim N(0, 1.007^2)
\end{equation} 
\]</span>
The estimated model is also close to the “true” model:</p>
<p><span class="math display">\[
y_t = 15 + 0.8x_{t-3} + 1.5x_{t-4} + \epsilon_t \\
\epsilon \sim N(0, 1)
\]</span>
### Autocorrelated residuals</p>
<p>While in the previous case a standard linear model works well, <em>often the residuals of times series regressions are autocorrelated</em>, and fitting a simple linear model gets wrong estimates. For instance, let’s create other two time series that are, as the previous ones, cross-correlated at lag 3 and 4, but with a bit more complicated structure.</p>
<div class="sourceCode" id="cb243"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb243-1"><a href="regression.html#cb243-1"></a><span class="co"># another set of simulated data </span></span>
<span id="cb243-2"><a href="regression.html#cb243-2"></a><span class="co"># the x series is correlated at lag 3 and 4</span></span>
<span id="cb243-3"><a href="regression.html#cb243-3"></a><span class="kw">set.seed</span>(<span class="dv">999</span>)</span>
<span id="cb243-4"><a href="regression.html#cb243-4"></a>x2_series &lt;-<span class="st"> </span><span class="kw">arima.sim</span>(<span class="dt">n =</span> <span class="dv">200</span>, <span class="kw">list</span>(<span class="dt">order =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>), <span class="dt">ar =</span> <span class="fl">0.7</span>, <span class="dt">sd=</span><span class="dv">1</span>))</span>
<span id="cb243-5"><a href="regression.html#cb243-5"></a>z2 &lt;-<span class="st"> </span><span class="kw">ts.intersect</span>(x2_series, stats<span class="op">::</span><span class="kw">lag</span>(x2_series, <span class="dv">-3</span>), stats<span class="op">::</span><span class="kw">lag</span>(x2_series, <span class="dv">-4</span>)) </span>
<span id="cb243-6"><a href="regression.html#cb243-6"></a>y2_series &lt;-<span class="st"> </span><span class="dv">15</span> <span class="op">+</span><span class="st"> </span><span class="fl">0.8</span><span class="op">*</span>z2[,<span class="dv">2</span>] <span class="op">+</span><span class="st"> </span><span class="fl">1.5</span><span class="op">*</span>z2[,<span class="dv">3</span>] </span>
<span id="cb243-7"><a href="regression.html#cb243-7"></a>y2_errors &lt;-<span class="st"> </span><span class="kw">arima.sim</span>(<span class="dt">n =</span> <span class="dv">196</span>, <span class="kw">list</span>(<span class="dt">order =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>), <span class="dt">ar =</span> <span class="fl">0.6</span>, <span class="dt">ma =</span> <span class="fl">0.6</span>), <span class="dt">sd=</span><span class="dv">1</span>)</span>
<span id="cb243-8"><a href="regression.html#cb243-8"></a>y2_series &lt;-<span class="st"> </span>y2_series <span class="op">+</span><span class="st"> </span>y2_errors</span>
<span id="cb243-9"><a href="regression.html#cb243-9"></a></span>
<span id="cb243-10"><a href="regression.html#cb243-10"></a>x2Lagged &lt;-<span class="st"> </span><span class="kw">cbind</span>(</span>
<span id="cb243-11"><a href="regression.html#cb243-11"></a>    <span class="dt">xLag0 =</span> x2_series,</span>
<span id="cb243-12"><a href="regression.html#cb243-12"></a>    <span class="dt">xLag3 =</span> stats<span class="op">::</span><span class="kw">lag</span>(x2_series,<span class="op">-</span><span class="dv">3</span>),</span>
<span id="cb243-13"><a href="regression.html#cb243-13"></a>    <span class="dt">xLag4 =</span> stats<span class="op">::</span><span class="kw">lag</span>(x2_series,<span class="op">-</span><span class="dv">4</span>))</span>
<span id="cb243-14"><a href="regression.html#cb243-14"></a></span>
<span id="cb243-15"><a href="regression.html#cb243-15"></a>xy2_series &lt;-<span class="st"> </span><span class="kw">ts.union</span>(y2_series, x2Lagged)</span>
<span id="cb243-16"><a href="regression.html#cb243-16"></a></span>
<span id="cb243-17"><a href="regression.html#cb243-17"></a><span class="co"># check the cross-correlations at lag 3 and 4</span></span>
<span id="cb243-18"><a href="regression.html#cb243-18"></a><span class="kw">library</span>(TSA)</span>
<span id="cb243-19"><a href="regression.html#cb243-19"></a><span class="kw">prewhiten</span>(x2_series, y2_series) </span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-166-1.png" width="672" /></p>
<p>Considering the autocorrelated structure of the series, the true model can be written as follows:</p>
<p><span class="math display">\[
\begin{aligned} 
&amp; y_t = 15 + 0.8x_{t-3} + 1.5x_{t-4} + \eta_t \\
&amp; \eta_t = 0.7\eta_{t-1} + \epsilon_t + 0.6\epsilon_{t-1} \\
&amp; \epsilon \sim N(0, 1)
\end{aligned} 
\]</span></p>
<div class="sourceCode" id="cb244"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb244-1"><a href="regression.html#cb244-1"></a>lm2 &lt;-<span class="st"> </span><span class="kw">lm</span>(xy2_series[,<span class="dv">1</span>] <span class="op">~</span><span class="st"> </span>xy2_series[,<span class="dv">3</span><span class="op">:</span><span class="dv">4</span>])</span>
<span id="cb244-2"><a href="regression.html#cb244-2"></a><span class="kw">summary</span>(lm2) <span class="co"># AIC: 821.45</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = xy2_series[, 1] ~ xy2_series[, 3:4])
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.9200 -1.4508  0.0667  1.5395  5.1083 
## 
## Coefficients:
##                                 Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)                      14.9005     0.1486 100.273  &lt; 2e-16 ***
## xy2_series[, 3:4]x2Lagged.xLag3   1.0407     0.1595   6.523 6.14e-10 ***
## xy2_series[, 3:4]x2Lagged.xLag4   1.5171     0.1599   9.488  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.028 on 189 degrees of freedom
##   (12 observations deleted due to missingness)
## Multiple R-squared:  0.6735, Adjusted R-squared:   0.67 
## F-statistic: 194.9 on 2 and 189 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>The estimated model is the following:</p>
<p><span class="math display">\[
\begin{aligned} 
&amp; y_t = 14.9005 + 1.0407x_{t-3} + 1.5171x_{t-4} + \epsilon_t \\
&amp; \epsilon \sim N(0, 2.028^2)
\end{aligned}
\]</span>
The original series can be also visualized with the fitted values (the values resulting from the model), to visually inspect the fit (how well the model represent the original series). The differences between the original and the fitted series are the residuals.</p>
<div class="sourceCode" id="cb246"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb246-1"><a href="regression.html#cb246-1"></a>lm2d &lt;-<span class="st"> </span><span class="kw">ts.intersect</span>(<span class="kw">na.omit</span>(xy2_series[,<span class="dv">1</span>]), lm2<span class="op">$</span>fitted.values)</span>
<span id="cb246-2"><a href="regression.html#cb246-2"></a><span class="kw">plot.ts</span>(lm2d, <span class="dt">plot.type =</span> <span class="st">&quot;single&quot;</span>, <span class="dt">col=</span><span class="kw">c</span>(<span class="st">&quot;orange&quot;</span>,<span class="st">&quot;blue&quot;</span>), </span>
<span id="cb246-3"><a href="regression.html#cb246-3"></a>        <span class="dt">lty=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">4</span>), <span class="dt">lwd=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>),</span>
<span id="cb246-4"><a href="regression.html#cb246-4"></a>        <span class="dt">main =</span> <span class="st">&quot;&#39;Classic&#39; Linear Model - Original (orange) and Fitted series (blue)&quot;</span>) </span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-168-1.png" width="672" /></p>
<p>The diagnostic plots of the residuals show the presence of autocorrelation, and the Breusch-Godfrey test is highly significant (its value is far lower than the critical value <span class="math inline">\(\alpha = 0.05\)</span>)</p>
<div class="sourceCode" id="cb247"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb247-1"><a href="regression.html#cb247-1"></a><span class="kw">checkresiduals</span>(lm2)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-169-1.png" width="672" /></p>
<pre><code>## 
##  Breusch-Godfrey test for serial correlation of order up to 10
## 
## data:  Residuals
## LM test = 149.45, df = 10, p-value &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb249"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb249-1"><a href="regression.html#cb249-1"></a><span class="kw">pacf</span>(lm2<span class="op">$</span>residuals)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-169-2.png" width="672" /></p>
<p>In this case, we have to take into account the residuals’ autocorrelation by using a regression model capable to handle autocorrelated time series structures.</p>
</div>
</div>
<div id="regression-with-arima-errors" class="section level2">
<h2><span class="header-section-number">9.3</span> Regression with ARIMA errors</h2>
<p>In the previous chapter we said that ARIMA models are a special type of regression model, in which the dependent variable is the time series itself, and the independent variables are all lags of the time series. This model is capable to take into account the <em>autocorrelated</em> structure of time series.</p>
<p>ARIMA is a modeling technique that can be applied to a single time series, but it can be extended to include additional, <strong>exogenous variables</strong>. The ARIMA model including exogenous regressors (i.e.: other time series besides the lagged dependent variable) is like a multiple regression models for time series. In particular, it can be considered a regression model capable to control for autocorrelation in residuals.</p>
<p>It is possible to use more than one option to fit an ARIMA model with external regressors. A convenient option is provided by the function <strong>auto.arima</strong>, in the package <em>forecast</em>. This library has an argument <strong>xreg</strong> which can be use with <em>a numerical vector or matrix of external regressors, which must have the same number of rows as y</em> (see ?auto.arima).</p>
<div class="sourceCode" id="cb250"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb250-1"><a href="regression.html#cb250-1"></a><span class="kw">set.seed</span>(<span class="dv">999</span>)</span>
<span id="cb250-2"><a href="regression.html#cb250-2"></a>arima1 &lt;-<span class="st"> </span><span class="kw">auto.arima</span>(xy2_series[,<span class="dv">1</span>], <span class="dt">xreg =</span> xy2_series[,<span class="dv">3</span><span class="op">:</span><span class="dv">4</span>])</span>
<span id="cb250-3"><a href="regression.html#cb250-3"></a>arima1</span></code></pre></div>
<pre><code>## Series: xy2_series[, 1] 
## Regression with ARIMA(1,0,1) errors 
## 
## Coefficients:
##          ar1     ma1  intercept  x2Lagged.xLag3  x2Lagged.xLag4
##       0.6863  0.6491    14.8532          0.9506          1.5732
## s.e.  0.0555  0.0528     0.3607          0.0757          0.0762
## 
## sigma^2 estimated as 0.9482:  log likelihood=-265.76
## AIC=543.52   AICc=543.97   BIC=563.06</code></pre>
<p>The resulting model seems to be more appropriate than the previous one, fitted by using just a “classic” linear regression. This is clear also by comparing the two models through the <a href="https://en.wikipedia.org/wiki/Akaike_information_criterion"><strong>AIC criterium (Akaike information criterion)</strong></a>. The AIC value is used to compare the <em>goodness-of-fit</em> of different models fitted to the same dataset. The lower the AIC value, the better the fit.</p>
<p>The auto.arima function prints the AIC value by default, while this value is not given with the <em>lm</em> function. To get it, we need to use the <strong>AIC</strong> function.</p>
<div class="sourceCode" id="cb252"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb252-1"><a href="regression.html#cb252-1"></a><span class="kw">AIC</span>(lm2)</span></code></pre></div>
<pre><code>## [1] 821.4495</code></pre>
<p>In this case, the ARIMA regression model results a far better model (<em>AIC=543.52</em>) compared with the classic linear model (<em>AIC=821.45</em>).</p>
<p><span class="math display">\[
\begin{aligned} 
&amp; y_t = 14.8532 + 0.9506x_{t-3} + 1.5732x_{t-4} + \eta_t \\
&amp; \eta_t = 0.6863\eta_{t-1} + \epsilon_t + 0.6491\epsilon_{t-1} \\
&amp; \epsilon \sim N(0, 0.9482)
\end{aligned} 
\]</span>
Diagnostic analysis of the residuals, shows that there is no concerning sign of autocorrelation in the residuals, which looks like white noise. Also the test for autocorrelated errors is not significant (the default test for autocorrelation when testing an ARIMA models with external regressors in the <em>forecast</em> package is the <strong>Ljung-Box test</strong>)<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>).</p>
<div class="sourceCode" id="cb254"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb254-1"><a href="regression.html#cb254-1"></a><span class="kw">checkresiduals</span>(arima1)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-172-1.png" width="672" /></p>
<pre><code>## 
##  Ljung-Box test
## 
## data:  Residuals from Regression with ARIMA(1,0,1) errors
## Q* = 6.3861, df = 5, p-value = 0.2704
## 
## Model df: 5.   Total lags used: 10</code></pre>
<p>Also by visually inspect the original series along with the fitted series (the values resulting from the model), it can be seen that the model is better than the previous one.</p>
<div class="sourceCode" id="cb256"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb256-1"><a href="regression.html#cb256-1"></a>arima1d &lt;-<span class="st"> </span><span class="kw">ts.intersect</span>(<span class="kw">na.omit</span>(xy2_series[,<span class="dv">1</span>]), arima1<span class="op">$</span>fitted)</span>
<span id="cb256-2"><a href="regression.html#cb256-2"></a><span class="kw">plot.ts</span>(arima1d, <span class="dt">plot.type =</span> <span class="st">&quot;single&quot;</span>, <span class="dt">col=</span><span class="kw">c</span>(<span class="st">&quot;orange&quot;</span>,<span class="st">&quot;blue&quot;</span>), </span>
<span id="cb256-3"><a href="regression.html#cb256-3"></a>        <span class="dt">lty=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">4</span>), <span class="dt">lwd=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>),</span>
<span id="cb256-4"><a href="regression.html#cb256-4"></a>        <span class="dt">main =</span> <span class="st">&quot;ARIMA errors model - Original (orange) and Fitted series (blue)&quot;</span>) </span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-173-1.png" width="672" /></p>
<p>We can also compare the fitted versus original values by using a scatterplot. A better model produces a thinner diagonal line.</p>
<div class="sourceCode" id="cb257"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb257-1"><a href="regression.html#cb257-1"></a><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb257-2"><a href="regression.html#cb257-2"></a><span class="kw">plot</span>(<span class="kw">na.omit</span>(xy2_series[,<span class="dv">1</span>]), lm2<span class="op">$</span>fitted.values, <span class="dt">main =</span> <span class="st">&quot;LM&quot;</span>, <span class="dt">xlab=</span><span class="st">&quot;Original&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;Fitted&quot;</span>)</span>
<span id="cb257-3"><a href="regression.html#cb257-3"></a><span class="kw">plot</span>(<span class="kw">na.omit</span>(xy2_series[,<span class="dv">1</span>]), arima1<span class="op">$</span>fitted, <span class="dt">main =</span> <span class="st">&quot;ARIMA regression model&quot;</span>, <span class="dt">xlab=</span><span class="st">&quot;Original&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;Fitted&quot;</span>)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-174-1.png" width="672" /></p>
</div>
<div id="some-examples-in-the-literature" class="section level2">
<h2><span class="header-section-number">9.4</span> Some examples in the literature</h2>
<p>There are several examples of the use of time series regression models in the literature in the field of communication science.</p>
<p>For instance, in <a href="https://ijoc.org/index.php/ijoc/article/viewFile/14843/3344">The Event-Centered Nature of Global Public Spheres: The UN Climate Change Conferences, Fridays for Future, and the (Limited) Transnationalization of Media Debates</a><a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a>, the authors <em>examined whether the UN climate change conferences are conducive to an emergence of a transnational public sphere by triggering issue convergence and increased transnational interconnectedness across national media debates</em>. They authors detail the method they follows in this way:</p>
<blockquote>
<p>[…] Given the autoregressive nature and other properties of time series, an ordinary least squares regression analysis would violate the normality of error and the independence of observations assumption (Wells et al., 2019). Instead, <strong>we applied the dynamic regression approach</strong> (Gujarati &amp; Porter, 2009; Hyndman &amp; Athanasopoulos, 2018), which assumes that the <strong>error term follows an autoregressive integrated moving average (ARIMA) model</strong> (…). we found the best ARIMA structure of the error term by using the <em>auto.arima function from the forecast R package</em> (Hyndman &amp; Khandakar, 2008). It searches for an ARIMA structure that can explain the most variance according to the <em>Akaike information criterion</em> (Akaike, 1973).</p>
</blockquote>
<p>In this case they use the term “dynamic regression” to refer to a time series regression with ARIMA errors, but they did not include lagged values of their variables, thus analyzing contemporary relationships between variables.</p>
<p>The found, for instance, that <em>events taking place on a supranational level of governance (…) consistently led to spikes in media attention across countries. In contrast, a bottom-up effort such as Fridays for Future showed an inconsistent relationship with media attention across the four countries.</em></p>
<p><img src="images/Event-Centered%20Nature%20of%20Global%20Public%20Spheres.png" width="756" /></p>
<p>In <a href="https://ijoc.org/index.php/ijoc/article/viewFile/11666/2819">Online incivility, cyberbalkanization, and the dynamics of opinion polarization during and after a mass protest event</a><a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a>, the authors used both standard regression and regression with ARIMA errors to show that <em>“online incivility — operationalized as the use of foul language — grew as volume of political discussions and levels of cyberbalkanization increased. Incivility led to higher levels of opinion polarization.”</em>. Also in this case the authors analyze a “static process”, that is, focus on contemporary relationships between variables.</p>
<p><img src="images/Online-Incivility.png" width="854" /></p>
<p>In <a href="https://journals.sagepub.com/doi/abs/10.1177/1077699013493792">Beyond cognitions: A longitudinal study of online search salience and media coverage of the president</a><a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a>, the authors used regression models with ARIMA errors to examine <em>shifts in newswire coverage and search interest among Internet users in President Obama during the first two years of his administration (2009-2010)</em>.</p>
<p><img src="images/Beyond-Cognitions.png" width="550" /></p>
<p>In this case, the authors analyze relationships between variables taking into account lagged values, thus adopting a “dynamic process” perspective. For instance, they write:</p>
<blockquote>
<p>RQ2 sought to determine the time span of linkages between coverage volume and search volume. (…) <strong>ARIMA</strong> models were run to gauge the <em>dynamics</em> of mutual influence between these two time series. The first model examined the effect of coverage volume on search volume over time (i.e., basic agenda setting) (…) presidential public relations, was included as an additional input series. The first model, with search volume being a single dependent variable, was <strong>identified</strong> through a <strong>close examination of autocorrelation functions (ACFs) and partial autocorrelation functions (PACFs)</strong>. This analysis revealed a classic <strong>autoregressive model for the series (1, 0, 0)</strong>. […] According to the results, <em>shifts in aggregate search volume over this two-year period were significantly</em> <strong>predicted by coverage volume over the prior five weeks</strong> (p &lt; .010)* and by presidential public relations efforts in the preceding two, three (p &lt; .001), and five weeks (p &lt; .005). The ARIMA model with two predictors was correctly specified (<strong>Ljung–Box Q</strong> = 18.132, p = .381) and it explained roughly 35% of the observed variation in the series.</p>
</blockquote>
<p>In <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4126885/">AIDS in black and white: The influence of newspaper coverage of HIV/AIDS on HIV/AIDS testing among African Americans and White Americans, 1993–2007</a><a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a>, the authors <em>examined the effect of newspaper coverage of HIV/AIDS on HIV testing behavior in a U.S. population.</em>, using a <em>lagged regression</em> to support <em>causal order claims by ensuring that newspaper coverage precedes the testing behavior with the inclusion of the 1-month lagged newspaper coverage variable in the model</em>. Counterintuitively, they found that the news media coverage had a negative effect on testing behavior: <em>For every additional 100 HIV/AIDS risk related newspaper stories published in this group of U.S. newspapers each month, there was a 1.7% decline in HIV testing levels in the following month</em>, with a higher negative effects on African Americans.</p>
<p><img src="images/AIDS%20in%20Black%20and%20White.png" width="520" /></p>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>1) Linearity: The relationship between X and Y must be linear; 2) Independence of errors: There is not a relationship between the residuals and the Y variable; 3) Normality of errors: The residuals must be approximately normally distributed; 4) Equal variances: The variance of the residuals is the same for all values of X<a href="regression.html#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>There are many tests for detecting autocorrelation. Besides the already mentioned <em>Breusch-Godfrey test</em> and <em>Ljung-Box test</em>, other popular tests are the <em>Durbin Watson test</em>, and the <em>Box–Pierce test</em>. Each test has its own characteristics. For instance, the Durbin-Watson test is a popular way to test for autocorrelation, but it <a href="https://www.jstor.org/stable/pdf/1909870.pdf?refreqid=excelsior%3A9526730d9debe4fa8f1a4d5fa601d523">shouldn’t be used with lagged dependent variables</a>. In this case it can be used the Breusch-Godfrey test<a href="regression.html#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>Wozniak, A., Wessler, H., Chan, C. H., &amp; Lück, J. (2021). The Event-Centered Nature of Global Public Spheres: The UN Climate Change Conferences, Fridays for Future, and the (Limited) Transnationalization of Media Debates. <em>International Journal of Communication</em>, 15(27)<a href="regression.html#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>Lee, F. L., Liang, H., &amp; Tang, G. K. (2019). Online incivility, cyberbalkanization, and the dynamics of opinion polarization during and after a mass protest event. International Journal of Communication, 13, 20.<a href="regression.html#fnref4" class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p>Ragas, M. W., &amp; Tran, H. (2013). Beyond cognitions: A longitudinal study of online search salience and media coverage of the president. Journalism &amp; Mass Communication Quarterly, 90(3), 478-499.<a href="regression.html#fnref5" class="footnote-back">↩︎</a></p></li>
<li id="fn6"><p>Stevens, R., &amp; Hornik, R. C. (2014). AIDS in black and white: The influence of newspaper coverage of HIV/AIDS on HIV/AIDS testing among African Americans and White Americans, 1993–2007. Journal of health communication, 19(8), 893-906<a href="regression.html#fnref6" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="correlations-and-arima.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="intervention-analysis.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/nicolarighetti/Introduction-to-Time-Series-Analysis-With-R/edit/master/08-Regression.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/nicolarighetti/Introduction-to-Time-Series-Analysis-With-R/blob/master/08-Regression.Rmd",
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
