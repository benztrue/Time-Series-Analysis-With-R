[["index.html", "Time Series Analysis With R Chapter 1 Time Series Analysis With R 1.1 Objectives 1.2 Lectures 1.3 Home Work 1.4 Assessment 1.5 Syllabus and readings 1.6 Further information and support", " Time Series Analysis With R Nicola Righetti 2021-04-13 Chapter 1 Time Series Analysis With R This book will be updated as the course goes on. 1.1 Objectives This course is a practical introduction to time series analysis with R. It will introduce students to: The specificity of time series data; The free statistical software R to conduct time series analysis; Some of the main univariate and multivariate techniques to analyze time series data. At the end of the course, the students are expected to know the specificity of time series data and to be able to use R to perform simple time series analysis by applying the techniques described during the course. 1.2 Lectures 12 lectures (Thursday 11:30-13:00). Structure of the course: Theoretical concepts: this part of the course will introduce students to the main theoretical concepts of time series analysis; R Tutorial: this part of the course consists in a hands-on tutorial on the R functions necessary to perform time series analysis. Every part of a time series analysis project will be taken into account, including data wrangling, visual representation, and statistical analysis; Individual/Group work: this part of the course consists in individual and group work based on the application of the theoretical and practical knowledge described in the previous part of the course 1.3 Home Work Theoretical concepts can be studied, but you have to practice in order to learn R. 1.4 Assessment Assignments distributed during the course, dealing with demonstrating the understanding of key concepts (30%). A final data analysis project where participants will apply the knowledge and techniques learned during the course (70%). 1.5 Syllabus and readings This open book is specifically created for the 220050-1 SE SE Advanced Data Analysis 2 (2021S) course. It includes both theoretical concepts and the R tutorial with the necessary code to perform all the operations we are going to learn. The book also includes hyperlinks to additional free resources and readings. The mandatory readings will be listed in the Readings section of the book. A new part of the book will be uploaded online every weeks, following the program of the lessons. The link to this book is the following: Time-Series-Analysis-With-R. 1.6 Further information and support For any information, communication, or request for clarification, you can reach out to me at my University of Vienna address. "],["getting-started-with-r.html", "Chapter 2 Getting started with R 2.1 RStudio Interface and Data 2.2 Basic R", " Chapter 2 Getting started with R 2.1 RStudio Interface and Data 2.1.1 Download and Install RStudio This course is based on the statistical software R. R is easier to use in the development environment RStudio (it works on both Windows, Apple, and other OS). It is possible to download a free version of RStudio Desktop from the official websites. You might also use a free online version of RStudio by registering to the RStudio Cloud free plan. However, the free plan gives you just 15 hours per months. Our lessons take 4.5 hours per month, and since you also need to practice, the best choice is to install RStudio and R on your computer. Now we are going to see how to get started with RStudio Desktop. First, download and install a free version of RStudio Desktop and open the software. 2.1.2 Create a RStudio Project and Import data When starting a data analysis project with RStudio, we create a new dedicated environment where we will keep all the scripts (files containing the code to perform the analysis), data sets, and outputs of the analysis (such as plots and tables). This dedicated work-space is simply called a project. To create a new project with RStudio, follows these steps: click on File (on the top left); then, click on New Project; select New Directory, and New Project; choose a folder for the project, and give a name to your project. You can use the name Time-Series-Analysis-With-R; In this way, it will be created a new folder for the project, in the main folder specified in the previous step. In this folder, you will find a file .Rproj, the name of which is the name you assigned to your project. To work on this project, you just need to open the .Rproj file. 2.1.3 Create a Script Once the project has been created, we can open a new script and save it. A script is a file containing code. We can create a first script named basic-r-syntax, where you will test the basic code we are going to see. The script will be saved with extension .r. You can open, change, and save the file every time you work on it. To save your code is important, otherwise you would have to write the same code every time you work on the project! Create and save a script Update a script and run code 2.1.4 The RStudio User Interface The interface of RStudio is organized in four main quadrants: The top-left quadrant is the editor. Here you can create or open a script and compose the R commands. The top-right quadrant shows the R workspace, which holds the data and other objects you have created in the current R session. The bottom-right quadrant is a window for graphics output, but it also has tabs to manage your file directories, R packages, and the R Help facility. On the bottom left is the R Console window, where the code gets executed and the output is produced. You can run the commands, sending the code from the editor to the console, by highlighting it and hitting the Run button, or the Ctrl-Enter key combination. It is also possible to type and run commands directly into the console window (in this case, nothing will be saved). The top-right quadrant shows the R workspace, which holds the data and other objects you have created in the current R session. There is the file tab, where you can navigate files and folders and find, for instance, the data sets you want to upload. The bottom-right quadrant is a window for graphics output. Here you can visualize your plots. There is also a tab for the R packages, and the R Help facility. 2.1.5 Load and Save Data To load data into R you can click on the file window in the top-right quadrant, navigate your files/folders, and once you have found your data set file, you can just click it and follow the semi-automated import procedure. Import Data Otherwise, you can upload a data set by using a function. For instance, to import a csv file, one of the most common format for data sets, it can be employed the function read.csv. The main argument of this function is the path of the file you want to upload. To specify the file path, consider that you are working within a specific environment, that is, your working directory is the folder of the project (you can double check the working directory you are working in, by running the command getwd()). Thus, to indicate the path of the data set you want to upload, you can write a dot followed by a slash ./, followed by the path of the data set inside the working directory. For instance, in the case below, the data set is saved in a folder named data inside the working directory. The name of the data set is tweets_vienna and its extension is .csv. Therefore, the code to upload the file is as follows: fake_news &lt;- read.csv(&quot;./data/fake-news-stories-over-time-20210111144200.csv&quot;) To save data there are a few options. Generally, if you want to save a data set, you can opt for the .csv or the .rds format. The .rds format is only readable by R, while the .csv is a “universal” format (you can read it with Excel, for instance). To save a file as .csv it can be used the function write.csv. The main arguments of this function are the name of the object that has to be saved, the path to the folder where the object will be saved, and the name we want to assign to the file. write.csv(fake_news, file = &quot;./data/fake_news.csv&quot;) To save .rds file the procedure is similar, but the saveRDS function has to be employed. Instead, to read an rds file, the appropriate function is readRDS. saveRDS(fake_news, file = &quot;./data/fake_news.rds&quot;) fake_news &lt;- readRDS(&quot;./data/fake_news.rds&quot;) # read a .rds file In the code above you can notice an hash mark sign followed by some text. It is a comment. Comments are textual content used to describe the code in order to make it easier to understand and reuse it. Comments are written after the hash mark sign (#), because the text written after the hash mark sign is ignored by R: you can read the comments, but R does not consider them as code. 2.1.6 Create new Folders It is a good practice to create, in the main folder of the project, sub-folders dedicated to different type of files used in the project, such as a folder “data” for the data sets. To create a new folder you can go to the Files windows in the RStudio interface, click New Folder, and give it a name. 2.2 Basic R 2.2.1 Objects An object is an R entity composed of a name and a value. The arrow (&lt;-) sign is used to create objects and assign a value to an object (or to change or “update” its previous value). Example: create an object with name “object_consisting_of_a_number” and value equal 2: object_consisting_of_a_number &lt;- 2 Enter the name of the object in the console and run the command: the value assigned to the object will be printed. object_consisting_of_a_number ## [1] 2 The object is equal to its value. Therefore, for instance, an object with a numerical value can be used to perform arithmetical operations. object_consisting_of_a_number * 10 ## [1] 20 The value of an object can be transformed: object_consisting_of_a_number &lt;- object_consisting_of_a_number * 10 object_consisting_of_a_number ## [1] 20 An object can also represent a function. Example: create an object for the sum (addition) function: function_sum &lt;- function(x, y){ result &lt;- x + y return(result) } The function can now be applied to two numerical values: function_sum(5, 2) ## [1] 7 Actually, we don’t need this function, since mathematical functions are already implemented in R. sum(5, 2) ## [1] 7 5 + 7 ## [1] 12 2 * 3 ## [1] 6 3^2 ## [1] 9 sqrt(9) ## [1] 3 The value of an object can be a number, a function, but also a vector. Vectors are sequences of values. vector_of_numbers &lt;- c(1,2,3,4,5,6,7,8,9,10) vector_of_numbers ## [1] 1 2 3 4 5 6 7 8 9 10 A vector of numbers can be the argument of mathematical operations. vector_of_numbers * 2 ## [1] 2 4 6 8 10 12 14 16 18 20 vector_of_numbers + 3 ## [1] 4 5 6 7 8 9 10 11 12 13 Other R objects are matrix, list, and data.frame. A matrix is a table composed of rows and columns containing only numerical values. a_matrix &lt;- matrix(data = 1:50, nrow = 10, ncol = 5) a_matrix ## [,1] [,2] [,3] [,4] [,5] ## [1,] 1 11 21 31 41 ## [2,] 2 12 22 32 42 ## [3,] 3 13 23 33 43 ## [4,] 4 14 24 34 44 ## [5,] 5 15 25 35 45 ## [6,] 6 16 26 36 46 ## [7,] 7 17 27 37 47 ## [8,] 8 18 28 38 48 ## [9,] 9 19 29 39 49 ## [10,] 10 20 30 40 50 A list is just a list of other objects. For instance, this list includes a numerical value, a vectors of numbers, and a matrix. a_list &lt;- list(object_consisting_of_a_number, vector_of_numbers, a_matrix) a_list ## [[1]] ## [1] 20 ## ## [[2]] ## [1] 1 2 3 4 5 6 7 8 9 10 ## ## [[3]] ## [,1] [,2] [,3] [,4] [,5] ## [1,] 1 11 21 31 41 ## [2,] 2 12 22 32 42 ## [3,] 3 13 23 33 43 ## [4,] 4 14 24 34 44 ## [5,] 5 15 25 35 45 ## [6,] 6 16 26 36 46 ## [7,] 7 17 27 37 47 ## [8,] 8 18 28 38 48 ## [9,] 9 19 29 39 49 ## [10,] 10 20 30 40 50 A data.frame is like a matrix that can contain numbers but also other types of data, such as characters (a textual type of data), or factors (unordered categorical variables, such as gender, or ordered categories, such as low, medium, high). Data sets are usually stored in data.frame. For instance, if you import a csv or an Excel file in R, the corresponding R object is a data.frame. # this is an object (vector) consisting of a series of numerical values numerical_vector &lt;- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14) numerical_vector ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # this is another object (vector) consisting of a series of categorical values categorical_vector &lt;- c(&quot;Monday&quot;, &quot;Tuesday&quot;, &quot;Monday&quot;, &quot;Tuesday&quot;, &quot;Monday&quot;, &quot;Wednesday&quot;,&quot;Thursday&quot;, &quot;Wednesday&quot;, &quot;Thursday&quot;, &quot;Saturday&quot;, &quot;Sunday&quot;, &quot;Friday&quot;, &quot;Saturday&quot;, &quot;Sunday&quot;) categorical_vector ## [1] &quot;Monday&quot; &quot;Tuesday&quot; &quot;Monday&quot; &quot;Tuesday&quot; &quot;Monday&quot; &quot;Wednesday&quot; &quot;Thursday&quot; &quot;Wednesday&quot; &quot;Thursday&quot; ## [10] &quot;Saturday&quot; &quot;Sunday&quot; &quot;Friday&quot; &quot;Saturday&quot; &quot;Sunday&quot; # this is an object consisting of a data.frame, created combining vectors through the function &quot;data.frame&quot; a_dataframe &lt;- data.frame(&quot;first_variable&quot; = numerical_vector, &quot;second_variable&quot; = categorical_vector) a_dataframe ## first_variable second_variable ## 1 1 Monday ## 2 2 Tuesday ## 3 3 Monday ## 4 4 Tuesday ## 5 5 Monday ## 6 6 Wednesday ## 7 7 Thursday ## 8 8 Wednesday ## 9 9 Thursday ## 10 10 Saturday ## 11 11 Sunday ## 12 12 Friday ## 13 13 Saturday ## 14 14 Sunday To access a specific column of a data.frame, you can use the name of the data.frame, the dollar symbol $, and the name of the column. a_dataframe$first_variable ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 a_dataframe$second_variable ## [1] Monday Tuesday Monday Tuesday Monday Wednesday Thursday Wednesday Thursday Saturday Sunday ## [12] Friday Saturday Sunday ## Levels: Friday Monday Saturday Sunday Thursday Tuesday Wednesday It is possible to add columns to a data.frame by writing: the name of the data.frame the dollar sign a name for the new column the arrow sign &lt;- a vector of values to be stored in the new column (it has to have length equal to the other vectors composing the data.frame) a_dataframe$a_new_variable &lt;- c(12, 261, 45, 29, 54, 234, 45, 42, 6, 267, 87, 3, 12, 9) a_dataframe ## first_variable second_variable a_new_variable ## 1 1 Monday 12 ## 2 2 Tuesday 261 ## 3 3 Monday 45 ## 4 4 Tuesday 29 ## 5 5 Monday 54 ## 6 6 Wednesday 234 ## 7 7 Thursday 45 ## 8 8 Wednesday 42 ## 9 9 Thursday 6 ## 10 10 Saturday 267 ## 11 11 Sunday 87 ## 12 12 Friday 3 ## 13 13 Saturday 12 ## 14 14 Sunday 9 It is possible to visualize the first few rows of a data.frame by using the function head. head(a_dataframe) ## first_variable second_variable a_new_variable ## 1 1 Monday 12 ## 2 2 Tuesday 261 ## 3 3 Monday 45 ## 4 4 Tuesday 29 ## 5 5 Monday 54 ## 6 6 Wednesday 234 Exercise: visualize the first rows of a data.frame and access its columns 2.2.2 Functions A function is a coded operation that applies to an object (e.g.: a number, a textual feature etc.) to transform it based on specific rules. A function has a name (the name of the function) and some arguments. Among the arguments of a function there is always an object or a value, for instance a numerical value, which is the content the function is applied to, and other possible arguments (either mandatory or optional). Functions are operations applied to objects that give a certain output. E.g.: the arithmetical operation “addition” is a function that applies to two or more numbers to give, as its output, their sum. The arguments of the “sum” function are the numbers that are added together. The name of the function is written out of parentheses, and the arguments of the function inside the parentheses: sum(5, 3) ## [1] 8 Arguments of functions can be numbers but also textual features. For instance, the function paste creates a string composed of the strings that it takes as arguments. paste(&quot;the&quot;, &quot;cat&quot;, &quot;is&quot;, &quot;at&quot;, &quot;home&quot;) ## [1] &quot;the cat is at home&quot; In R you can sometimes find a “nested” syntax, which can be confusing. The best practice is to keep things as simple as possible. # this comment, written after the hash mark, describe what is going on here: two &quot;paste&quot; function nested together have been used (improperly! because they make the code more complicated than necessary) to show how functions can be nested together. It would have been better to use the &quot;paste&quot; function just one time! paste(paste(&quot;the&quot;, &quot;cat&quot;, &quot;is&quot;, &quot;at&quot;, &quot;home&quot;), &quot;and&quot;, &quot;sleeps&quot;, &quot;on&quot;, &quot;the&quot;, &quot;sofa&quot;) ## [1] &quot;the cat is at home and sleeps on the sofa&quot; To sum up, functions manipulate and transform objects. Data wrangling, data visualization, as well as data analysis, are performed through functions. 2.2.3 Data Types Variables can have different R formats, such as: double: numbers that include decimals (0.1, 5.676, 121.67). This format is appropriate for continuous variables; integer: such as 1, 2, 3, 10, 400. It is a format suitable to count data; factors: for categorical variables. Factors can be ordered (e.g.: level of agreement: “high”, “medium”, “low”), or not (e.g.: hair colors “blond”, “dark brown”, “brown”); characters: textual labels; logicals: the format of logical values (i.e.: TRUE and FALSE) dates: used to represent days; POSIX: a class of R format to represent dates and times. Figure 2.1: R data formats. Tables from Gaubatz, K. T. (2014). A Survivor’s Guide to R: An Introduction for the Uninitiated and the Unnerved. SAGE Publications. It is better to specify the appropriate type of data when importing a data set. In the example below, the data format are specified by using the import process of RStudio. Notice that the data of type “date” requires users to specify the additional information regarding the format of the dates. Indeed, dates can be written in many different ways, and to read dates in R it is necessary to specify the structure of the date. In the example, dates are in the format Year-Month-Day, which is represented in R as “%Y-%m-%d” (further details will be provided in another section of the book). Import data and specify data types 2.2.4 Excercise Upload the data set “election news small”, using the appropriate data format; Open the script “basic-r-script” and perform the following operations: Check the first few rows of the data set; Access the single columns; Save the data frame with the name “election_news_small_test” in the folder “data” by using the function “write.csv” (to review the procedure go to the section “Load and Save Data” on this book); Comment the code (the comments have to be written after the hash sign #); Save the script. "],["basic-data-wrangling-with-tidyverse.html", "Chapter 3 Basic Data Wrangling with Tidyverse 3.1 The Pipe Operator %&gt;% 3.2 Mutate 3.3 Rename 3.4 Summarize and group_by 3.5 Arrange 3.6 Filter 3.7 Select 3.8 Exercise", " Chapter 3 Basic Data Wrangling with Tidyverse Data wrangling is the process of transforming and mapping data from one “raw” data form into another format with the intent of making it more appropriate and valuable for a variety of downstream purposes such as analytics. The goal of data wrangling is to assure quality and useful data. Data analysts typically spend the majority of their time in the process of data wrangling compared to the actual analysis of the data. Another definition is as follows: Data wrangling is the process of profiling and transforming datasets to ensure they are actionable for a set of analysis tasks. One central goal is to make data usable: to put data in a form that can be parsed and manipulated by analysis tools. Another goal is to ensure that data is responsive to the intended analyses: that the data contain the necessary information, at an acceptable level of description and correctness, to support successful modeling and decision-making. How to “manipulate” data sets in R: use basic R functions; employ specific libraries such as tidyverse. Tidyverse is an R library composed of functions that allow users to perform basic and advanced data science operations. https://www.tidyverse.org. In R, a library (or “package”) is a coherent collection of functions, usually created for specific purposes. To work with the tidyverse library, it is necessary to install it first, by using the following command: install.packages(“tidyverse”). After having installed tidyverse (or any other library), it is necessary to load it, so as we can work with its functions in the current R session: # to load a library used the command library(NAME-OF-THE-LIBRARY) library(tidyverse) Besides using the function install.packages(NAME-OF-THE-LIBRARY) by using a line of code, it is also possible to use the RStudio interface. Install and Load a Library 3.1 The Pipe Operator %&gt;% Tidyverse has a peculiar syntax that makes use of the so-called pipe operator %&gt;%, like in the following example: a_dataframe %&gt;% group_by(second_variable) %&gt;% summarize(mean = mean(a_new_variable)) ## `summarise()` ungrouping output (override with `.groups` argument) ## # A tibble: 7 x 2 ## second_variable mean ## &lt;fct&gt; &lt;dbl&gt; ## 1 Friday 3 ## 2 Monday 37 ## 3 Saturday 140. ## 4 Sunday 48 ## 5 Thursday 25.5 ## 6 Tuesday 145 ## 7 Wednesday 138 To manipulate data sets are useful the functions included in dplyr: a grammar of data manipulation, providing a consistent set of verbs that help you solve the most common data manipulation challenges, such as mutate, rename, summarize. library(readr) tweets &lt;- read_csv(&quot;data/tweets_covid_small.csv&quot;, col_types = cols(created_at = col_datetime(format = &quot;%Y-%m-%d %H:%M:%S&quot;), retweet_count = col_integer())) head(tweets) ## # A tibble: 6 x 4 ## created_at screen_name source retweet_count ## &lt;dttm&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 2021-03-24 08:53:52 DoYourThingUK Twitter for iPhone 0 ## 2 2021-03-24 08:53:25 DoYourThingUK Twitter for iPhone 0 ## 3 2021-03-24 08:53:52 AlexS1595 Twitter for iPhone 3 ## 4 2021-03-24 08:53:51 MakesworthAcc Twitter Web App 0 ## 5 2021-03-24 08:53:39 MakesworthAcc Twitter Web App 4 ## 6 2021-03-24 08:53:51 GGrahambute Twitter for iPad 96 Import data and specify data types (dates and times) 3.2 Mutate The function mutate adds new variables to a data.frame or overwrite existing variables. tweets &lt;- tweets %&gt;% mutate(log_retweet_count = log(retweet_count)) head(tweets) ## # A tibble: 6 x 5 ## created_at screen_name source retweet_count log_retweet_count ## &lt;dttm&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 2021-03-24 08:53:52 DoYourThingUK Twitter for iPhone 0 -Inf ## 2 2021-03-24 08:53:25 DoYourThingUK Twitter for iPhone 0 -Inf ## 3 2021-03-24 08:53:52 AlexS1595 Twitter for iPhone 3 1.10 ## 4 2021-03-24 08:53:51 MakesworthAcc Twitter Web App 0 -Inf ## 5 2021-03-24 08:53:39 MakesworthAcc Twitter Web App 4 1.39 ## 6 2021-03-24 08:53:51 GGrahambute Twitter for iPad 96 4.56 3.3 Rename Rename is a function to change the name of columns (sometimes it could be useful). tweets &lt;- tweets %&gt;% # rename (new_name = old_name) rename(device = source) head(tweets) ## # A tibble: 6 x 5 ## created_at screen_name device retweet_count log_retweet_count ## &lt;dttm&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 2021-03-24 08:53:52 DoYourThingUK Twitter for iPhone 0 -Inf ## 2 2021-03-24 08:53:25 DoYourThingUK Twitter for iPhone 0 -Inf ## 3 2021-03-24 08:53:52 AlexS1595 Twitter for iPhone 3 1.10 ## 4 2021-03-24 08:53:51 MakesworthAcc Twitter Web App 0 -Inf ## 5 2021-03-24 08:53:39 MakesworthAcc Twitter Web App 4 1.39 ## 6 2021-03-24 08:53:51 GGrahambute Twitter for iPad 96 4.56 The previous two steps can be performed at the same time, by concatenating the operations through the pipe %&gt;% operator. # load again the data set library(readr) tweets &lt;- read_csv(&quot;data/tweets_covid_small.csv&quot;, col_types = cols(created_at = col_datetime(format = &quot;%Y-%m-%d %H:%M:%S&quot;), retweet_count = col_integer())) tweets &lt;- tweets %&gt;% mutate(log_retweet_count = log(retweet_count+1)) %&gt;% rename(device = source) head(tweets) ## # A tibble: 6 x 5 ## created_at screen_name device retweet_count log_retweet_count ## &lt;dttm&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 2021-03-24 08:53:52 DoYourThingUK Twitter for iPhone 0 0 ## 2 2021-03-24 08:53:25 DoYourThingUK Twitter for iPhone 0 0 ## 3 2021-03-24 08:53:52 AlexS1595 Twitter for iPhone 3 1.39 ## 4 2021-03-24 08:53:51 MakesworthAcc Twitter Web App 0 0 ## 5 2021-03-24 08:53:39 MakesworthAcc Twitter Web App 4 1.61 ## 6 2021-03-24 08:53:51 GGrahambute Twitter for iPad 96 4.57 To check the data format of the variables stored in the data.frame can be used the command str(): str(tweets) ## tibble [100 × 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame) ## $ created_at : POSIXct[1:100], format: &quot;2021-03-24 08:53:52&quot; &quot;2021-03-24 08:53:25&quot; &quot;2021-03-24 08:53:52&quot; &quot;2021-03-24 08:53:51&quot; ... ## $ screen_name : chr [1:100] &quot;DoYourThingUK&quot; &quot;DoYourThingUK&quot; &quot;AlexS1595&quot; &quot;MakesworthAcc&quot; ... ## $ device : chr [1:100] &quot;Twitter for iPhone&quot; &quot;Twitter for iPhone&quot; &quot;Twitter for iPhone&quot; &quot;Twitter Web App&quot; ... ## $ retweet_count : int [1:100] 0 0 3 0 4 96 0 1 0 3 ... ## $ log_retweet_count: num [1:100] 0 0 1.39 0 1.61 ... ## - attr(*, &quot;spec&quot;)= ## .. cols( ## .. created_at = col_datetime(format = &quot;%Y-%m-%d %H:%M:%S&quot;), ## .. screen_name = col_character(), ## .. source = col_character(), ## .. retweet_count = col_integer() ## .. ) Sometimes variables are stored in the data.frame in the wrong format (see the paragraph “data type”) and we want to convert them into a new data format. For this purpose we can use, again, the function mutate, along with other functions such as.integer, as.numeric, as.character, as.factors, or as.logical, as.Date, or as.POSIXct() based on the desired data format (it is possible and advisable to upload the data by paying attention to the type of data so as this step is not necessary). tweets %&gt;% mutate(device = as.character(device)) %&gt;% head() ## # A tibble: 6 x 5 ## created_at screen_name device retweet_count log_retweet_count ## &lt;dttm&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 2021-03-24 08:53:52 DoYourThingUK Twitter for iPhone 0 0 ## 2 2021-03-24 08:53:25 DoYourThingUK Twitter for iPhone 0 0 ## 3 2021-03-24 08:53:52 AlexS1595 Twitter for iPhone 3 1.39 ## 4 2021-03-24 08:53:51 MakesworthAcc Twitter Web App 0 0 ## 5 2021-03-24 08:53:39 MakesworthAcc Twitter Web App 4 1.61 ## 6 2021-03-24 08:53:51 GGrahambute Twitter for iPad 96 4.57 3.4 Summarize and group_by To aggregate data and calculate synthetic values (for instance, the average number of tweets by day), it can be used the function group_by (to aggregate data, for instance by day), and summarize, to calculate the summary values. tweets_summary &lt;- tweets %&gt;% group_by(screen_name) %&gt;% summarize(average_retweets = mean(retweet_count)) head(tweets_summary) ## # A tibble: 6 x 2 ## screen_name average_retweets ## &lt;chr&gt; &lt;dbl&gt; ## 1 2EXvoZ6nublpw1F 164 ## 2 AdilHaiderMD 80 ## 3 AlexS1595 3 ## 4 Andecave 20 ## 5 anshunandanpra4 2 ## 6 ApKido 150 It is also possible to create many different summary variable at once. tweets_summary &lt;- tweets %&gt;% group_by(screen_name) %&gt;% summarize(average_retweets = mean(retweet_count), average_log_retweets = mean(log_retweet_count)) head(tweets_summary) ## # A tibble: 6 x 3 ## screen_name average_retweets average_log_retweets ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2EXvoZ6nublpw1F 164 5.11 ## 2 AdilHaiderMD 80 4.39 ## 3 AlexS1595 3 1.39 ## 4 Andecave 20 3.04 ## 5 anshunandanpra4 2 1.10 ## 6 ApKido 150 5.02 3.4.1 Count occurrences A useful operation to perform when summarizing data, is to count the occurrences of a certain variable (mostly qualitative). For instance, to count the number of tweets sent by each user, it can be used the function n() inside the summarize function. tweets_summary &lt;- tweets %&gt;% group_by(screen_name) %&gt;% summarize(average_retweets = mean(retweet_count), average_log_retweets = mean(log_retweet_count), number_of_tweets = n()) head(tweets_summary) ## # A tibble: 6 x 4 ## screen_name average_retweets average_log_retweets number_of_tweets ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2EXvoZ6nublpw1F 164 5.11 1 ## 2 AdilHaiderMD 80 4.39 1 ## 3 AlexS1595 3 1.39 1 ## 4 Andecave 20 3.04 1 ## 5 anshunandanpra4 2 1.10 1 ## 6 ApKido 150 5.02 1 3.5 Arrange To explore a data set it can be useful to sort the data (e.g.: from the lowest to the highest number of a variable). With tidyverse, we can order a data.frame by using the function arrange. To sort the data from the highest to the lowest values (a descending order) the minus sign (or the “desc” function) has to be added. tweets_summary %&gt;% arrange(-number_of_tweets) %&gt;% head() ## # A tibble: 6 x 4 ## screen_name average_retweets average_log_retweets number_of_tweets ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 iprdhzb 0.667 0.462 3 ## 2 benphillips76 3.5 1.45 2 ## 3 DoYourThingUK 0 0 2 ## 4 MakesworthAcc 2 0.805 2 ## 5 viralvideovlogs 3.5 1.45 2 ## 6 2EXvoZ6nublpw1F 164 5.11 1 tweets_summary %&gt;% arrange(desc(average_retweets)) %&gt;% head() ## # A tibble: 6 x 4 ## screen_name average_retweets average_log_retweets number_of_tweets ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 Oliver_Miguel1 1988 7.60 1 ## 2 Lil_3arbiii 1627 7.40 1 ## 3 Kittyhawk681 1285 7.16 1 ## 4 JulesFox12 1091 7.00 1 ## 5 rosaesaa26 983 6.89 1 ## 6 lewisabzueta 822 6.71 1 Without minus sign (or “desc” function), the data are sorted from the lowest to the highest value. tweets_summary %&gt;% arrange(number_of_tweets) %&gt;% head() ## # A tibble: 6 x 4 ## screen_name average_retweets average_log_retweets number_of_tweets ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2EXvoZ6nublpw1F 164 5.11 1 ## 2 AdilHaiderMD 80 4.39 1 ## 3 AlexS1595 3 1.39 1 ## 4 Andecave 20 3.04 1 ## 5 anshunandanpra4 2 1.10 1 ## 6 ApKido 150 5.02 1 3.6 Filter The function filter keeps the cases we want to focus on. The arguments of this function represent a condition that has to be fulfilled: the name of the column that has to be filtered, and the column values to be kept. tweets %&gt;% filter(retweet_count &gt;= 500) %&gt;% arrange(-retweet_count) ## # A tibble: 10 x 5 ## created_at screen_name device retweet_count log_retweet_count ## &lt;dttm&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 2021-03-24 08:53:31 Oliver_Miguel1 Twitter for Android 1988 7.60 ## 2 2021-03-24 08:53:48 Lil_3arbiii Twitter for iPhone 1627 7.40 ## 3 2021-03-24 08:53:48 Kittyhawk681 Twitter Web App 1285 7.16 ## 4 2021-03-24 08:53:37 JulesFox12 Twitter for Android 1091 7.00 ## 5 2021-03-24 08:53:42 rosaesaa26 Twitter for Android 983 6.89 ## 6 2021-03-24 08:53:42 lewisabzueta Twitter for Android 822 6.71 ## 7 2021-03-24 08:53:42 jonvthvn08 Twitter for iPhone 768 6.65 ## 8 2021-03-24 08:53:34 florent61647053 Twitter for Android 768 6.65 ## 9 2021-03-24 08:53:37 Ritu89903967 Twitter for Android 709 6.57 ## 10 2021-03-24 08:53:33 Hurica3 Twitter for iPhone 575 6.36 In the examples below, notice the use of a double equal sign ==, and also of the quotation marks to include textual categories. tweets %&gt;% filter(retweet_count == 1988) ## # A tibble: 1 x 5 ## created_at screen_name device retweet_count log_retweet_count ## &lt;dttm&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 2021-03-24 08:53:31 Oliver_Miguel1 Twitter for Android 1988 7.60 tweets %&gt;% filter(device == &quot;Twitter for Android&quot;) ## # A tibble: 33 x 5 ## created_at screen_name device retweet_count log_retweet_count ## &lt;dttm&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 2021-03-24 08:53:49 marcin_lukawski Twitter for Android 1 0.693 ## 2 2021-03-24 08:53:49 LebodyRanya Twitter for Android 0 0 ## 3 2021-03-24 08:53:47 anshunandanpra4 Twitter for Android 2 1.10 ## 4 2021-03-24 08:53:44 insoumise007 Twitter for Android 5 1.79 ## 5 2021-03-24 08:53:43 Metamorfopsies Twitter for Android 0 0 ## 6 2021-03-24 08:53:43 keepsmiling_130 Twitter for Android 164 5.11 ## 7 2021-03-24 08:53:43 lovebresil01 Twitter for Android 81 4.41 ## 8 2021-03-24 08:53:42 LightHealing Twitter for Android 1 0.693 ## 9 2021-03-24 08:53:42 lewisabzueta Twitter for Android 822 6.71 ## 10 2021-03-24 08:53:42 rosaesaa26 Twitter for Android 983 6.89 ## # … with 23 more rows It is also possible to use multiple conditions at the same time. tweets %&gt;% filter(device == &quot;Twitter for Android&quot;, retweet_count &gt; 200) %&gt;% arrange(-retweet_count) ## # A tibble: 8 x 5 ## created_at screen_name device retweet_count log_retweet_count ## &lt;dttm&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 2021-03-24 08:53:31 Oliver_Miguel1 Twitter for Android 1988 7.60 ## 2 2021-03-24 08:53:37 JulesFox12 Twitter for Android 1091 7.00 ## 3 2021-03-24 08:53:42 rosaesaa26 Twitter for Android 983 6.89 ## 4 2021-03-24 08:53:42 lewisabzueta Twitter for Android 822 6.71 ## 5 2021-03-24 08:53:34 florent61647053 Twitter for Android 768 6.65 ## 6 2021-03-24 08:53:37 Ritu89903967 Twitter for Android 709 6.57 ## 7 2021-03-24 08:53:27 aspeaker66 Twitter for Android 331 5.81 ## 8 2021-03-24 08:53:42 JamesAn26254230 Twitter for Android 201 5.31 3.7 Select Select is used to keep just some of the columns of the original data.frame. For instance, we can apply the function in order to keep just the column “device” and “retweet_count”. tweets %&gt;% select(device, retweet_count) %&gt;% head() ## # A tibble: 6 x 2 ## device retweet_count ## &lt;chr&gt; &lt;int&gt; ## 1 Twitter for iPhone 0 ## 2 Twitter for iPhone 0 ## 3 Twitter for iPhone 3 ## 4 Twitter Web App 0 ## 5 Twitter Web App 4 ## 6 Twitter for iPad 96 3.8 Exercise Here are some exercises to consolidate the fundamental R skills learned during these first lessons: Download the csv file tweets_vienna_small.csv in this folder and put it into the project folder “data” Upload the data set in R, setting the appropriate formats for the variables Create a new script named “data-manipulation” with your surname and name as follows: “YOUR SURNAME-YOUR NAME-data-manipulation”, and save it In the script, write the code to perform the following operations: load the library “Tidyverse” show the first rows of the data frame by using the function head create a new data frame “tweets_vienna_small_updated” by updating the dataframe “tweets_vienna_small” by using the function mutate to create a new column “log_friends_count” whose values are the log of the values in the column “friends_count” (you don’t need to add 1 to the values in the column “friends_count”) save the updated dataframe “tweets_vienna_small_updated”, by using the following code to save a csv file (please change YOUR SURNAME-YOUR NAME with your actual surname and name): write.csv(tweets_vienna_small_updated, file = “./data/YOUR SURNAME-YOUR NAME-tweets_vienna_small_updated.csv”, row.names=F) (we add row.names=F to avoid saving the number that indexes each row) create a new data frame named “summary_tweets_vienna_small” aggregating the data by “screen_name” (using the function group_by) and then summarizing the data (by using the function summarize) as follows: in a column named “average_favorite_count”, calculate the average of “favorite_count” by “screen_name” (that is, by user) in a column named “average_retweet_count”, calculate the average of “retweet_count” (by user, obviously, since the data are already aggregated by user’ name) in a column named “number_of_tweets”, calculate the number of tweets published by each users (by using the function n()) save the “summary_tweets_vienna_small” in the data folder of the project, in csv format, and with the name “YOUR SURNAME-YOUR NAME-summary_tweets_vienna_small.csv” (remember to specify row.names=F and to change YOUR SURNAME-YOUR NAME with your actual surname and name) create a new data frame object called “summary_tweets_vienna_small_filtered”, where you will save the data.frame summary_tweets_vienna_small, after having filtered the rows with average_retweet_count higher than 10 (by using the function filter), and after having selected the column “screen_name” and “average_retweet_count” (so, you should end up with a data frame with just two columns, “screen_name” and “average_retweet_count”, and the rows with “average_retweet_count” higher than 10) save the data frame “summary_tweets_vienna_small_filtered” with the name “YOUR SURNAME-YOUR NAME-summary_tweets_vienna_small_filtered.csv” in the folder data (remember to specify row.names=F and to change YOUR SURNAME-YOUR NAME with your actual surname and name). Save the script “YOUR SURNAME-YOUR NAME-data-manipulation” with all the code you have used to perform these analysis. Write a comment in the script (using the hash mark #) if you are not able to do something. Upload the script “YOUR SURNAME-YOUR NAME-data-manipulation.r” and the files “YOUR SURNAME-YOUR NAME-tweets_vienna_small_updated.csv”, “YOUR SURNAME-YOUR NAME-summary_tweets_vienna_small.csv”, and the file “YOUR SURNAME-YOUR NAME-summary_tweets_vienna_small_filtered.csv” on Moodle, in the folder “HomeWork-1”. The deadline is Sunday 11 April. "],["basic-definitions.html", "Chapter 4 Basic Definitions 4.1 Time Series 4.2 Time Series Analysis 4.3 Stochastic and Deterministic Processes", " Chapter 4 Basic Definitions 4.1 Time Series A time series is a serially sequenced set of values representing a variable value at different points in time (VanLear, “Time Series Analysis”). It consists in measures collected through time, at regular time intervals, about an unit of observation, resulting in a set of ordered values. This regularity is the frequency of time series (which can be, for instance, an hourly, weekly, monthly, quarterly, yearly, etc.). Time series data are different from cross-sectional data, which are set of data observed on a sample of units taken at a given point in time, or where the time dimension is not relevant and can be ignored. Cross-sectional data are a snapshot of a population of interest at one particular point in time, while time series show the dynamical evolution of a variable over time. Panel data combine cross-sectional and time series data by observing the same units over time. Time is a fundamental variable in time series. It is often not relevant in other types of statistical analyses. Also from a sociological perspective (and psychological as well), we can see that past events influence future behaviors. Oftentimes, we can make reasonable prediction about future social behaviors just by observing past behaviors. Actually, social reproduction of behaviors over time and predictability of future social behaviors based on past experience and shared knowledge are essential to social order, and thus, a fundamental dimension of human society. From a statistical perspective, the impact of time resulting from repeated measurements over time on a single subject or unit, introduce a dependency among data points which prevent the use of some of the most common statistical techniques. In cross-sectional data, observations are assumed to be independent: values observed on one unit has no influence on values observed on other units. Time series observations have a different nature: a time series is not a collection of independent observations, or observations taken on independent units, but a collection of successive observations on the same unit. Observations are not taken across units at the same time (or without regards to time), but across time on the same unit. When dealing with time series data, time is an important factor to be taken into account. It introduce a new dimension to the data. For instance, we can calculate how the variable increases or decreases over time, if it peaks at a given moment in time, or at regular intervals. We consider not just if, and how much, a variable is correlated with another variable, but if there is a correlation over time among them, if the peaks in one variable precedes the peaks in the other one, or how much time it requires for a variable to have an impact on another one, and how much this impact changes over time. Importantly, when dealing with time series data, we have to to acknowledge that sampling adjacent points in time introduce a correlation in the data. This serial dependency creates correlated errors which violates the assumptions of many traditional statistical analyses and can bias the estimation of error for confidence intervals or significance tests. This characteristic of time series data, in general, precludes the use of common statistical approaches such as linear regression and correlation analysis, which assume the observations to be independent. The application of “standard” statistical techniques to time series data might lead to foolish, and totally unreliable results. For instance, the statisticians George Udny Yule wrote: «It is fairly familiar knowledge that we sometimes obtain between quantities varying with the time (time-variables) quite high correlations to which we cannot attach any physical significance whatever, although under the ordinary test the correlation would be held to be certainly “significant.” (…) the occurrence of such “nonsense-correlations” makes one mistrust the serious arguments that are sometimes put forward on the basis of correlations between time-series. […] When the successive x’s and y’s in a sample no longer form a random series, but a series in which successive terms are closely related to one another, the usual conceptions (of correlation, ed.) to which we are accustomed fail totally and entirely to apply» (Yule, G.U. (1926). Why do we sometimes get nonsense-correlations between Time-Series? A study in sampling and the nature of time-series. Journal of the royal statistical society, 89(1), 1-63.) A funny website reporting spurious time series correlation is tylervigen.com. Despite it is funny to see these improbable correlations, we have to keep in mind that adopting the right approach to analyze data is a serious issue when doing research. In a (paper on the American Journal of Political Science)[https://gking.harvard.edu/files/gking/files/epr.pdf] we can read, for instance: The results of the analysis below strongly suggest that the way event counts have been analyzed in hundreds of important political science studies have produced statistically and substantively unreliable results. Misspecification, inefficiency, bias, inconsistency, insufficiency, and other problems result from the unknowing application of two common methods that are without theoretical justification or empirical utility in this type of data. Due to the peculiarity of time series data, time series analysis has been developed as a specific statistical methodology appropriate for the analysis of time-dependent data. Time series analysis aims at providing an understanding of the underlying processes and patterns of change over time of a unit of observation and the relations between variables observed over time, handling the time structure of the data in a proper way. 4.2 Time Series Analysis Time series analysis is an approach employed in many disciplines. Almost every field of study has data characterized by a time development, and every phenomenon with a temporal dimension can be conceived as a time series, and can be analyzed through time series analysis methods. Time series analysis are an important part of data analysis in disciplines such as economics, to analyze, for instance, inflation trends, marketing to analyze the number of clients of a store or number of accesses to an e-commerce website, in demography to study the growth of national population overtime or trends in population ageing, in engineering to analyze radio frequencies, in neurology to analyze brain waves detected through electroencephalograms. Political science can be interested in studying patterns in alternation of political parties in government, and digital communication can be interested in using time series analysis to study series of tweets using an hashtag, the news media coverage on a certain topic, or the trends in users searches on search engines such as those provided by Google Trends. About the use of time series analysis in communication science, it can be observed that “Many of the major theories and models in our field contain time as a central player: the two-step flow, cultivation, spiral-of-silence, agenda-setting, framing, and communication mediation models, to name a few (Nabi &amp; Oliver, 2009). Each articulates a set of processes that play out in time: Messages work their way through media systems and networks, citizens perceive the world around them and decide to communicate, or not, and they make choices about participation, presumably as a product of a process that includes communication exposure. Indeed, the words that animate our field—effect, flow, influence, dynamic, cycle—reveal our understanding of communication as a process, and processes have temporal dimensions (Box-Steffensmeier, Freeman, Hitt, &amp; Pevehouse, 2014). The perspective of time series analysis can help expand our notions of time’s role in these dynamics. We see several ways in which we can become more attentive to time in our field”. Wells, C., Shah, D. V., Pevehouse, J. C., Foley, J., Lukito, J., Pelled, A., &amp; Yang, J. (2019). The Temporal Turn in Communication Research: Time Series Analyses Using Computational Approaches. International Journal of Communication (19328036), 13. “One of the most common applications of time series analyses in mass communication is in agenda-setting research. The approach is to correlate the national news coverage on a topic over time with public opinion or public policy on that topic, often to estimate lagged effects or the decay of effects over time. Likewise, both trends and cycles of television programming, viewing, and advertising, have been explored through time series analyses. In the interpersonal literature, the most popular and one of the most important applications of time series analysis has been the investigation of mutual adaptation in the form of patterns of reciprocity or compensation between conversational partners over the course of an interaction.” (C. Arthur VanLear, “Time Series Analysis”, in Allen, M. (Ed.). (2017). The SAGE encyclopedia of communication research methods. Sage Publications). In general, we can distinguish at least the following aims of a time series analysis study: DESCRIPTION: Description of a process characterized by an intrinsic temporal dimension. Simple eamples of questions are: is there an upward trend? Is there a peak at a certain point in time? Is there a regular pattern recurring every year, in a particular moment in time? Descriptive questions like these can be answered via descriptive time series analysis. EVALUATION: Evaluation of the impact of a certain event, occurring in a particular point in time, on a process. For instance: did a change in social media moderation policy, such as those that led to ban accounts linked to conspiracy theories, impacted on the quantity of fake news shared online by users? Specific time series techniques can be used to perform this kind of analysis. EXPLANATION: Explanation of a phenomenon characterized by a time series structure on the basis of related variables. For instance: does the quantity of news shared on Facebook help explaining the polarization of debate online? Does the volume of news media articles on a topic help explaining the growth of the debate online on the same topic? Inferential statistical techniques, such as regression models developed for time series, are used to answer questions like these. FORECASTING: Prediction of the future values of a process. For instance: can we expect that news media coverage on a certain topic keep growing in the near future? This is the subject of time series forecasting. We can also distinguish between univariate and multivariate time series analysis. Time series analysis can be used to explain the temporal dependencies within and between processes. By temporal dependency within a social process, we mean that the current value of a variable is, in part, a function of previous values of that same variable. To analyze univariate structure of time series, univariate techniques are used. Temporal dependency between social processes, conversely, indicates that the current value of a variable is in part a function of the previous values of other variables. Multivariate time series analysis are used to explain the relations between time series. Figure 4.1: Tweets about vaccines published around the introduction of the Law on mandatory vaccination in Italy Figure 4.2: News media articles on Trump published by a sample of newspapers. Data from the free online tool MediaCloud Figure 4.3: Google search trends for Donald Trump and Joe Biden. Data retrieved from the free online tool Google Trends 4.3 Stochastic and Deterministic Processes A general distinction can be made between time series, based on their deterministic or non-deterministic nature. A deterministic time series is one which can be explicitly expressed by an analytic expression. It has no random or probabilistic parts. It is always possible to predict its future behavior, and state how it behaved in the past. Deterministic processes are pretty rare when dealing with individual and social behavior! Predicting future behaviors of a crowd, of a person, of a social group, can be reasonably possible, sometimes, based on past behaviors and other contextual information, since human behavior is partly influenced by the past. However, it is not fully determined by the past. There is always a certain degree of uncertainty in the prediction; human behaviors are, generally speaking, not fully predictable. Social and individual behaviors, therefore, are non-deterministic. A non-deterministic time series cannot be fully described by an analytic expression. It has some random, or probabilistic component, that prevents its behavior from being explicitly described. It could be possible to say, in probabilistic terms, what its future behavior might be. However, there will always be a residual, unpredictable, component. A time series may be considered non-deterministic also because all the information necessary to describe it explicitly is not available, although it might be in principle, or because the nature of the generating process, or part of it, is inherently random. We can say that the time series analyzed in social science have always, at least, a stochastic component that makes them not totally deterministic. Since non-deterministic time series have a random component, they follow probabilistic rather than deterministic laws. Random data are not defined by explicit mathematical relations, but rather in statistical terms, that is, by probability distributions and parameters such as mean and variance. Non-deterministic time series can be analyzed by assuming that they are manifestations of probabilistic or stochastic processes. In order to provide a statistical setting for describing the character of data that seemingly fluctuate in a random fashion over time, we assume a time series can be defined as a collection of random variables indexed according to the order they are obtained in time. For example, we may consider a time series as a sequence of random variables, x1; x2; x3; …, where the random variable x1 denotes the value taken by the series at the first time point, the variable x2 denotes the value for the second time period, x3 denotes the value for the third time period, and so on. In general, a collection of random variables, {xt}, indexed by t is referred to as a stochastic process. (…) The observed values of a stochastic process are referred to as a realization of the stochastic process. (Shumway &amp; Stoffer (2016). Time series analysis and its applications. New York: Springer) The stochastic process is a model for the analysis of time series. An observed time series is conceived as a single, among many, possible realizations of a process that might have been observed. The abstract, theoretical totality of possible time series that could have been observed is called an ensemble, and represents a statistical population. Every member of the ensemble is a possible realization of the underlying stochastic process. From this perspective, a single time series can be conceived as one particular realization of a stochastic process drawn from a population. In statistics, the properties of the population are inferred from an observed sample, which is usually drawn in a random way from that population. In time series analysis, however, we usually don’t have a sample of time series drawn from a population. Oftentimes, we have just one time series, and we want to say something statistically significant based on the observation we can make on a single case. To deal with this circumstance, many time series analysis techniques requires that the analyzed time series follows specific assumptions. Time series data can also be transformed in a way that makes them suitable to be analyzed. The principal assumption of many time series techniques is stationarity, and an ideal-type of stationary process is the so called white noise. White noise and the important property of stationarity will study later in this course. To better introduce these concepts, however, it is useful to learn how to create time series objects in R, and how to plot time series to visually inspect their main characteristics. "],["readings.html", "Chapter 5 Readings 5.1 Bibliographical References", " Chapter 5 Readings This page will be updated as the course goes on. Wells, C., Shah, D. V., Pevehouse, J. C., Foley, J., Lukito, J., Pelled, A., &amp; Yang, J. (2019). The Temporal Turn in Communication Research: Time Series Analyses Using Computational Approaches. International Journal of Communication (19328036), 13. 5.1 Bibliographical References Gaubatz, K. T. (2014). A Survivor’s Guide to R: An Introduction for the Uninitiated and the Unnerved. SAGE Publications. "]]
