# Intervention Analysis

In this chapter we are going to see how to conduct a intervention analysis.

Intervention analysis is a method introduced by [Box and Tiao (1975)](https://www.jstor.org/stable/pdf/2285379.pdf)^[Box, G. E., & Tiao, G. C. (1975). Intervention analysis with applications to economic and environmental problems. Journal of the American Statistical association, 70(349), 70-79], which provides a framework for assessing *the effect of an intervention on a time series* under study. As summarized by Box and Tiao: *Given a known intervention, is there evidence that change in the series of the kind expected actually occurred, and, if so, what can be said of the nature and magnitude of the change?*.

Intervention analysis is a "quasi-experimental" design and an interesting approach to test whether *exogenous shocks*, such as, for instance, the introduction of a new policy, *impact on a time series process in a significant way*, that is, **by changing the mean function or trend** of a time series.

Interventions can have different impacts. For instance, an intervention can have an abrupt impact determining a permanent or temporary change, a sudden and short-lived change due to an event, or a more gradual yet permanent change. 

```{r  echo=FALSE, caption="Box-Steffensmeier, J. M., Freeman, J. R., Hitt, M. P., & Pevehouse, J. C. (2014). Time series analysis for the social sciences. Cambridge University Press"}
knitr::include_graphics("images/intervention.png")
```

To conduct such an analysis, it is necessary to know, at least, the date of the intervention. Regarding the statistical approach, different approaches are possible. ARIMA modeling is a classic choice, and we can come back to it later. Instead, we start from a more complex Bayesian approach implemented in the convenient package *CausalImpact* developed and used at Google to [estimate causal impacts in a quasi-experimental framework](https://www.youtube.com/watch?v=GTgZfCltMm8)^[CausalImpact 1.2.1, Brodersen et al., Annals of Applied Statistics (2015). http://google.github.io/CausalImpact/]. 

```{r  echo=FALSE, caption="The model used in the CasualImpact package. Image from Brodersen, K. H., Gallusser, F., Koehler, J., Remy, N., & Scott, S. L. (2015). Inferring causal impact using Bayesian structural time-series models. Annals of Applied Statistics, 9(1), 247-274."}
knitr::include_graphics("images/causal-impact.png")
```


```{r}
# Install and load the package
# install.packages("CausalImpact")
library(CausalImpact)
```

We use the simulated dataset used by the Google tutorial on the package, creating two time series $y$ and $x$ of length 100, simulating an abrupt intervention at time 71 determining a permanent increment of 10 points in the $y$ series.

```{r}
set.seed(1)
x1 <- 100 + arima.sim(model = list(ar = 0.999), n = 100)
y <- 1.2 * x1 + rnorm(100)
y[71:100] <- y[71:100] + 10
dat <- ts.intersect(y, x1)
```

Then, it is necessary to specify the pre-intervention and post-intervention period. In the pre-intervention period no impact is expected.

```{r}
pre.period <- c(1, 70)
post.period <- c(71, 100)
```

The function *CausalImpact* uses the values of the original time series $y$ in the pre-intervention period, and the predictors correlated to the $y$ (in this case $x$), to forecast the values that $y$ would have had without the intervention (*counterfactual*). 

To accurately forecast the $y$ values, which is necessary to obtain valid results from the analysis, it is necessary to have a proper model of the $y$ series (based on the series itself and its predictors). Then, the differences in the expected (forecasted) $y$ values without intervention, and the actual $y$ values following the intervention, are compared in order to estimate the impact of the intervention.

```{r}
impact <- CausalImpact(dat, pre.period, post.period)
```

By using the function *plot* on the resulting model, three plots are visualized: 

>The first panel shows the data and a counterfactual prediction for the post-treatment period. The second panel shows the difference between observed data and counterfactual predictions. This is the pointwise causal effect, as estimated by the model. The third panel adds up the pointwise contributions from the second panel, resulting in a plot of the cumulative effect of the intervention. (...) the above inferences depend critically on the assumption that the covariates were not themselves affected by the intervention. The model also assumes that the relationship between covariates and treated time series, as established during the pre-period, remains stable throughout the post-period.

```{r}
plot(impact)
```

Besides plotting the results, it is possible to create a summary of the model, and by adding the argument "report" inside the function *summary*, a convenient explanations of the results is printed.

```{r}
summary(impact)
```

```{r}
summary(impact, "report")
```

The authors of the package underline the importance of the statistical assumptions to get valid results, and about possible strategies to ascertain that the assumptions are met, they write the following advice:

>Here are a few ways of getting started. First of all, it is critical to reason why the covariates that are included in the model (this was x1 in the example) were not themselves affected by the intervention. Sometimes it helps to plot all covariates and do a visual sanity check. Next, it is a good idea to examine how well the outcome data y can be predicted before the beginning of the intervention. This can be done by running CausalImpact() on an imaginary intervention. Then check how well the model predicted the data following this imaginary intervention. We would expect not to find a significant effect, i.e., counterfactual estimates and actual data should agree reasonably closely. Finally, when presenting or writing up results, be sure to list the above assumptions explicitly, including the priors in model.args, and discuss them with your audience.




